2025-02-24 06:43:36,123:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-24 06:43:36,123:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-24 06:43:36,123:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-24 06:43:36,123:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-24 06:45:10,729:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-24 06:45:10,729:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-24 06:45:10,729:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-24 06:45:10,729:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-02-24 06:45:16,650:INFO:PyCaret ClassificationExperiment
2025-02-24 06:45:16,650:INFO:Logging name: clf-default-name
2025-02-24 06:45:16,650:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-24 06:45:16,650:INFO:version 3.3.2
2025-02-24 06:45:16,650:INFO:Initializing setup()
2025-02-24 06:45:16,650:INFO:self.USI: 4ebd
2025-02-24 06:45:16,650:INFO:self._variable_keys: {'idx', 'html_param', 'log_plots_param', 'y_train', 'data', 'n_jobs_param', 'exp_id', 'y', 'X_test', 'exp_name_log', 'logging_param', 'pipeline', 'X_train', 'fold_shuffle_param', 'memory', 'y_test', 'gpu_n_jobs_param', 'seed', 'USI', '_ml_usecase', 'is_multiclass', 'target_param', '_available_plots', 'gpu_param', 'fold_generator', 'X', 'fix_imbalance', 'fold_groups_param'}
2025-02-24 06:45:16,650:INFO:Checking environment
2025-02-24 06:45:16,650:INFO:python_version: 3.11.11
2025-02-24 06:45:16,650:INFO:python_build: ('main', 'Dec  4 2024 08:55:07')
2025-02-24 06:45:16,650:INFO:machine: x86_64
2025-02-24 06:45:16,650:INFO:platform: Linux-6.1.85+-x86_64-with-glibc2.35
2025-02-24 06:45:16,651:INFO:Memory: svmem(total=13609431040, available=12117204992, percent=11.0, used=1156243456, free=4289019904, active=984768512, inactive=7834337280, buffers=529907712, cached=7634259968, shared=2600960, slab=407851008)
2025-02-24 06:45:16,651:INFO:Physical Core: 1
2025-02-24 06:45:16,651:INFO:Logical Core: 2
2025-02-24 06:45:16,651:INFO:Checking libraries
2025-02-24 06:45:16,652:INFO:System:
2025-02-24 06:45:16,652:INFO:    python: 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]
2025-02-24 06:45:16,652:INFO:executable: /usr/bin/python3
2025-02-24 06:45:16,652:INFO:   machine: Linux-6.1.85+-x86_64-with-glibc2.35
2025-02-24 06:45:16,652:INFO:PyCaret required dependencies:
2025-02-24 06:45:19,809:INFO:                 pip: 24.1.2
2025-02-24 06:45:19,810:INFO:          setuptools: 75.1.0
2025-02-24 06:45:19,810:INFO:             pycaret: 3.3.2
2025-02-24 06:45:19,810:INFO:             IPython: 7.34.0
2025-02-24 06:45:19,810:INFO:          ipywidgets: 7.7.1
2025-02-24 06:45:19,810:INFO:                tqdm: 4.67.1
2025-02-24 06:45:19,810:INFO:               numpy: 1.26.4
2025-02-24 06:45:19,810:INFO:              pandas: 2.1.4
2025-02-24 06:45:19,810:INFO:              jinja2: 3.1.5
2025-02-24 06:45:19,810:INFO:               scipy: 1.11.4
2025-02-24 06:45:19,810:INFO:              joblib: 1.3.2
2025-02-24 06:45:19,810:INFO:             sklearn: 1.4.2
2025-02-24 06:45:19,810:INFO:                pyod: 2.0.3
2025-02-24 06:45:19,810:INFO:            imblearn: 0.13.0
2025-02-24 06:45:19,810:INFO:   category_encoders: 2.7.0
2025-02-24 06:45:19,810:INFO:            lightgbm: 4.5.0
2025-02-24 06:45:19,810:INFO:               numba: 0.61.0
2025-02-24 06:45:19,810:INFO:            requests: 2.32.3
2025-02-24 06:45:19,810:INFO:          matplotlib: 3.7.5
2025-02-24 06:45:19,810:INFO:          scikitplot: 0.3.7
2025-02-24 06:45:19,810:INFO:         yellowbrick: 1.5
2025-02-24 06:45:19,810:INFO:              plotly: 5.24.1
2025-02-24 06:45:19,810:INFO:    plotly-resampler: Not installed
2025-02-24 06:45:19,810:INFO:             kaleido: 0.2.1
2025-02-24 06:45:19,810:INFO:           schemdraw: 0.15
2025-02-24 06:45:19,811:INFO:         statsmodels: 0.14.4
2025-02-24 06:45:19,811:INFO:              sktime: 0.26.0
2025-02-24 06:45:19,811:INFO:               tbats: 1.1.3
2025-02-24 06:45:19,811:INFO:            pmdarima: 2.0.4
2025-02-24 06:45:19,811:INFO:              psutil: 5.9.5
2025-02-24 06:45:19,811:INFO:          markupsafe: 3.0.2
2025-02-24 06:45:19,811:INFO:             pickle5: Not installed
2025-02-24 06:45:19,811:INFO:         cloudpickle: 3.1.1
2025-02-24 06:45:19,811:INFO:         deprecation: 2.1.0
2025-02-24 06:45:19,811:INFO:              xxhash: 3.5.0
2025-02-24 06:45:19,811:INFO:           wurlitzer: 3.1.1
2025-02-24 06:45:19,811:INFO:PyCaret optional dependencies:
2025-02-24 06:45:20,855:INFO:                shap: 0.46.0
2025-02-24 06:45:20,855:INFO:           interpret: Not installed
2025-02-24 06:45:20,855:INFO:                umap: Not installed
2025-02-24 06:45:20,855:INFO:     ydata_profiling: Not installed
2025-02-24 06:45:20,855:INFO:  explainerdashboard: Not installed
2025-02-24 06:45:20,855:INFO:             autoviz: Not installed
2025-02-24 06:45:20,855:INFO:           fairlearn: Not installed
2025-02-24 06:45:20,855:INFO:          deepchecks: Not installed
2025-02-24 06:45:20,855:INFO:             xgboost: 2.1.4
2025-02-24 06:45:20,855:INFO:            catboost: Not installed
2025-02-24 06:45:20,855:INFO:              kmodes: Not installed
2025-02-24 06:45:20,855:INFO:             mlxtend: 0.23.4
2025-02-24 06:45:20,855:INFO:       statsforecast: Not installed
2025-02-24 06:45:20,856:INFO:        tune_sklearn: Not installed
2025-02-24 06:45:20,856:INFO:                 ray: Not installed
2025-02-24 06:45:20,856:INFO:            hyperopt: 0.2.7
2025-02-24 06:45:20,856:INFO:              optuna: Not installed
2025-02-24 06:45:20,856:INFO:               skopt: Not installed
2025-02-24 06:45:20,856:INFO:              mlflow: Not installed
2025-02-24 06:45:20,856:INFO:              gradio: Not installed
2025-02-24 06:45:20,856:INFO:             fastapi: Not installed
2025-02-24 06:45:20,856:INFO:             uvicorn: Not installed
2025-02-24 06:45:20,856:INFO:              m2cgen: Not installed
2025-02-24 06:45:20,856:INFO:           evidently: Not installed
2025-02-24 06:45:20,856:INFO:               fugue: Not installed
2025-02-24 06:45:20,856:INFO:           streamlit: Not installed
2025-02-24 06:45:20,856:INFO:             prophet: 1.1.6
2025-02-24 06:45:20,856:INFO:None
2025-02-24 06:45:20,856:INFO:Set up data.
2025-02-24 06:45:20,908:INFO:Set up folding strategy.
2025-02-24 06:45:20,909:INFO:Set up train/test split.
2025-02-24 06:45:20,958:INFO:Set up index.
2025-02-24 06:45:20,958:INFO:Assigning column types.
2025-02-24 06:45:20,985:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-24 06:45:21,173:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-24 06:45:21,178:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-24 06:45:21,286:INFO:Soft dependency imported: xgboost: 2.1.4
2025-02-24 06:45:21,307:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-24 06:45:21,445:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-24 06:45:21,453:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-24 06:45:21,579:INFO:Soft dependency imported: xgboost: 2.1.4
2025-02-24 06:45:21,585:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-24 06:45:21,585:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-24 06:45:21,715:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-24 06:45:21,765:INFO:Soft dependency imported: xgboost: 2.1.4
2025-02-24 06:45:21,769:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-24 06:45:21,845:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-24 06:45:21,909:INFO:Soft dependency imported: xgboost: 2.1.4
2025-02-24 06:45:21,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-24 06:45:21,914:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-24 06:45:22,044:INFO:Soft dependency imported: xgboost: 2.1.4
2025-02-24 06:45:22,048:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-24 06:45:22,158:INFO:Soft dependency imported: xgboost: 2.1.4
2025-02-24 06:45:22,162:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-24 06:45:22,163:INFO:Preparing preprocessing pipeline...
2025-02-24 06:45:22,165:INFO:Set up label encoding.
2025-02-24 06:45:22,165:INFO:Set up simple imputation.
2025-02-24 06:45:22,173:INFO:Set up encoding of ordinal features.
2025-02-24 06:45:22,180:INFO:Set up encoding of categorical features.
2025-02-24 06:45:22,471:INFO:Finished creating preprocessing pipeline.
2025-02-24 06:45:22,515:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'balance', 'day',
                                             'duration', 'campaign', 'pdays',
                                             'previous'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['marital', 'education', 'contact',
                                             'month', 'poutcome'],
                                    transformer=OneHotEncoder(cols=['marital',
                                                                    'education',
                                                                    'contact',
                                                                    'month',
                                                                    'poutcome'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-02-24 06:45:22,515:INFO:Creating final display dataframe.
2025-02-24 06:45:23,130:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8              Numeric features   
9          Categorical features   
10                   Preprocess   
11              Imputation type   
12           Numeric imputation   
13       Categorical imputation   
14     Maximum one-hot encoding   
15              Encoding method   
16               Fold Generator   
17                  Fold Number   
18                     CPU Jobs   
19                      Use GPU   
20               Log Experiment   
21              Experiment Name   
22                          USI   

                                                Value  
0                                                4169  
1                                                 job  
2                                          Multiclass  
3   admin.: 0, blue-collar: 1, entrepreneur: 2, ho...  
4                                          (4521, 17)  
5                                          (4521, 38)  
6                                          (3164, 38)  
7                                          (1357, 38)  
8                                                   7  
9                                                   9  
10                                               True  
11                                             simple  
12                                               mean  
13                                               mode  
14                                                 25  
15                                               None  
16                                    StratifiedKFold  
17                                                 10  
18                                                 -1  
19                                              False  
20                                              False  
21                                   clf-default-name  
22                                               4ebd  
2025-02-24 06:45:23,249:INFO:Soft dependency imported: xgboost: 2.1.4
2025-02-24 06:45:23,253:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-24 06:45:23,365:INFO:Soft dependency imported: xgboost: 2.1.4
2025-02-24 06:45:23,369:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-24 06:45:23,372:INFO:setup() successfully completed in 6.74s...............
2025-02-24 06:45:23,501:INFO:PyCaret ClassificationExperiment
2025-02-24 06:45:23,501:INFO:Logging name: clf-default-name
2025-02-24 06:45:23,501:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-02-24 06:45:23,501:INFO:version 3.3.2
2025-02-24 06:45:23,501:INFO:Initializing setup()
2025-02-24 06:45:23,501:INFO:self.USI: f7ea
2025-02-24 06:45:23,501:INFO:self._variable_keys: {'idx', 'html_param', 'log_plots_param', 'y_train', 'data', 'n_jobs_param', 'exp_id', 'y', 'X_test', 'exp_name_log', 'logging_param', 'pipeline', 'X_train', 'fold_shuffle_param', 'memory', 'y_test', 'gpu_n_jobs_param', 'seed', 'USI', '_ml_usecase', 'is_multiclass', 'target_param', '_available_plots', 'gpu_param', 'fold_generator', 'X', 'fix_imbalance', 'fold_groups_param'}
2025-02-24 06:45:23,501:INFO:Checking environment
2025-02-24 06:45:23,501:INFO:python_version: 3.11.11
2025-02-24 06:45:23,501:INFO:python_build: ('main', 'Dec  4 2024 08:55:07')
2025-02-24 06:45:23,501:INFO:machine: x86_64
2025-02-24 06:45:23,501:INFO:platform: Linux-6.1.85+-x86_64-with-glibc2.35
2025-02-24 06:45:23,501:INFO:Memory: svmem(total=13609431040, available=11885539328, percent=12.7, used=1388068864, free=3926913024, active=985296896, inactive=8198381568, buffers=530309120, cached=7764140032, shared=2600960, slab=411230208)
2025-02-24 06:45:23,502:INFO:Physical Core: 1
2025-02-24 06:45:23,502:INFO:Logical Core: 2
2025-02-24 06:45:23,502:INFO:Checking libraries
2025-02-24 06:45:23,502:INFO:System:
2025-02-24 06:45:23,502:INFO:    python: 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]
2025-02-24 06:45:23,502:INFO:executable: /usr/bin/python3
2025-02-24 06:45:23,502:INFO:   machine: Linux-6.1.85+-x86_64-with-glibc2.35
2025-02-24 06:45:23,502:INFO:PyCaret required dependencies:
2025-02-24 06:45:23,502:INFO:                 pip: 24.1.2
2025-02-24 06:45:23,502:INFO:          setuptools: 75.1.0
2025-02-24 06:45:23,502:INFO:             pycaret: 3.3.2
2025-02-24 06:45:23,502:INFO:             IPython: 7.34.0
2025-02-24 06:45:23,502:INFO:          ipywidgets: 7.7.1
2025-02-24 06:45:23,502:INFO:                tqdm: 4.67.1
2025-02-24 06:45:23,502:INFO:               numpy: 1.26.4
2025-02-24 06:45:23,502:INFO:              pandas: 2.1.4
2025-02-24 06:45:23,502:INFO:              jinja2: 3.1.5
2025-02-24 06:45:23,502:INFO:               scipy: 1.11.4
2025-02-24 06:45:23,503:INFO:              joblib: 1.3.2
2025-02-24 06:45:23,503:INFO:             sklearn: 1.4.2
2025-02-24 06:45:23,503:INFO:                pyod: 2.0.3
2025-02-24 06:45:23,503:INFO:            imblearn: 0.13.0
2025-02-24 06:45:23,503:INFO:   category_encoders: 2.7.0
2025-02-24 06:45:23,503:INFO:            lightgbm: 4.5.0
2025-02-24 06:45:23,503:INFO:               numba: 0.61.0
2025-02-24 06:45:23,503:INFO:            requests: 2.32.3
2025-02-24 06:45:23,503:INFO:          matplotlib: 3.7.5
2025-02-24 06:45:23,503:INFO:          scikitplot: 0.3.7
2025-02-24 06:45:23,503:INFO:         yellowbrick: 1.5
2025-02-24 06:45:23,503:INFO:              plotly: 5.24.1
2025-02-24 06:45:23,503:INFO:    plotly-resampler: Not installed
2025-02-24 06:45:23,503:INFO:             kaleido: 0.2.1
2025-02-24 06:45:23,503:INFO:           schemdraw: 0.15
2025-02-24 06:45:23,503:INFO:         statsmodels: 0.14.4
2025-02-24 06:45:23,503:INFO:              sktime: 0.26.0
2025-02-24 06:45:23,503:INFO:               tbats: 1.1.3
2025-02-24 06:45:23,503:INFO:            pmdarima: 2.0.4
2025-02-24 06:45:23,503:INFO:              psutil: 5.9.5
2025-02-24 06:45:23,503:INFO:          markupsafe: 3.0.2
2025-02-24 06:45:23,503:INFO:             pickle5: Not installed
2025-02-24 06:45:23,503:INFO:         cloudpickle: 3.1.1
2025-02-24 06:45:23,503:INFO:         deprecation: 2.1.0
2025-02-24 06:45:23,503:INFO:              xxhash: 3.5.0
2025-02-24 06:45:23,503:INFO:           wurlitzer: 3.1.1
2025-02-24 06:45:23,503:INFO:PyCaret optional dependencies:
2025-02-24 06:45:23,503:INFO:                shap: 0.46.0
2025-02-24 06:45:23,503:INFO:           interpret: Not installed
2025-02-24 06:45:23,503:INFO:                umap: Not installed
2025-02-24 06:45:23,503:INFO:     ydata_profiling: Not installed
2025-02-24 06:45:23,503:INFO:  explainerdashboard: Not installed
2025-02-24 06:45:23,503:INFO:             autoviz: Not installed
2025-02-24 06:45:23,503:INFO:           fairlearn: Not installed
2025-02-24 06:45:23,503:INFO:          deepchecks: Not installed
2025-02-24 06:45:23,504:INFO:             xgboost: 2.1.4
2025-02-24 06:45:23,504:INFO:            catboost: Not installed
2025-02-24 06:45:23,504:INFO:              kmodes: Not installed
2025-02-24 06:45:23,504:INFO:             mlxtend: 0.23.4
2025-02-24 06:45:23,504:INFO:       statsforecast: Not installed
2025-02-24 06:45:23,504:INFO:        tune_sklearn: Not installed
2025-02-24 06:45:23,504:INFO:                 ray: Not installed
2025-02-24 06:45:23,504:INFO:            hyperopt: 0.2.7
2025-02-24 06:45:23,504:INFO:              optuna: Not installed
2025-02-24 06:45:23,504:INFO:               skopt: Not installed
2025-02-24 06:45:23,504:INFO:              mlflow: Not installed
2025-02-24 06:45:23,504:INFO:              gradio: Not installed
2025-02-24 06:45:23,504:INFO:             fastapi: Not installed
2025-02-24 06:45:23,504:INFO:             uvicorn: Not installed
2025-02-24 06:45:23,504:INFO:              m2cgen: Not installed
2025-02-24 06:45:23,504:INFO:           evidently: Not installed
2025-02-24 06:45:23,504:INFO:               fugue: Not installed
2025-02-24 06:45:23,504:INFO:           streamlit: Not installed
2025-02-24 06:45:23,504:INFO:             prophet: 1.1.6
2025-02-24 06:45:23,504:INFO:None
2025-02-24 06:45:23,504:INFO:Set up data.
2025-02-24 06:45:23,520:INFO:Set up folding strategy.
2025-02-24 06:45:23,520:INFO:Set up train/test split.
2025-02-24 06:45:23,535:INFO:Set up index.
2025-02-24 06:45:23,535:INFO:Assigning column types.
2025-02-24 06:45:23,541:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-02-24 06:45:23,614:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-24 06:45:23,616:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-24 06:45:23,689:INFO:Soft dependency imported: xgboost: 2.1.4
2025-02-24 06:45:23,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-24 06:45:23,776:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-02-24 06:45:23,777:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-24 06:45:23,820:INFO:Soft dependency imported: xgboost: 2.1.4
2025-02-24 06:45:23,825:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-24 06:45:23,826:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-02-24 06:45:23,902:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-24 06:45:23,948:INFO:Soft dependency imported: xgboost: 2.1.4
2025-02-24 06:45:23,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-24 06:45:24,003:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-02-24 06:45:24,026:INFO:Soft dependency imported: xgboost: 2.1.4
2025-02-24 06:45:24,028:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-24 06:45:24,029:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-02-24 06:45:24,090:INFO:Soft dependency imported: xgboost: 2.1.4
2025-02-24 06:45:24,092:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-24 06:45:24,153:INFO:Soft dependency imported: xgboost: 2.1.4
2025-02-24 06:45:24,156:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-24 06:45:24,157:INFO:Preparing preprocessing pipeline...
2025-02-24 06:45:24,158:INFO:Set up label encoding.
2025-02-24 06:45:24,159:INFO:Set up simple imputation.
2025-02-24 06:45:24,163:INFO:Set up encoding of ordinal features.
2025-02-24 06:45:24,167:INFO:Set up encoding of categorical features.
2025-02-24 06:45:24,371:INFO:Finished creating preprocessing pipeline.
2025-02-24 06:45:24,422:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'balance', 'day',
                                             'duration', 'campaign', 'pdays',
                                             'previous'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['marital', 'education', 'contact',
                                             'month', 'poutcome'],
                                    transformer=OneHotEncoder(cols=['marital',
                                                                    'education',
                                                                    'contact',
                                                                    'month',
                                                                    'poutcome'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-02-24 06:45:24,422:INFO:Creating final display dataframe.
2025-02-24 06:45:25,130:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8              Numeric features   
9          Categorical features   
10                   Preprocess   
11              Imputation type   
12           Numeric imputation   
13       Categorical imputation   
14     Maximum one-hot encoding   
15              Encoding method   
16               Fold Generator   
17                  Fold Number   
18                     CPU Jobs   
19                      Use GPU   
20               Log Experiment   
21              Experiment Name   
22                          USI   

                                                Value  
0                                                 123  
1                                                 job  
2                                          Multiclass  
3   admin.: 0, blue-collar: 1, entrepreneur: 2, ho...  
4                                          (4521, 17)  
5                                          (4521, 38)  
6                                          (3164, 38)  
7                                          (1357, 38)  
8                                                   7  
9                                                   9  
10                                               True  
11                                             simple  
12                                               mean  
13                                               mode  
14                                                 25  
15                                               None  
16                                    StratifiedKFold  
17                                                 10  
18                                                 -1  
19                                              False  
20                                              False  
21                                   clf-default-name  
22                                               f7ea  
2025-02-24 06:45:25,287:INFO:Soft dependency imported: xgboost: 2.1.4
2025-02-24 06:45:25,292:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-24 06:45:25,417:INFO:Soft dependency imported: xgboost: 2.1.4
2025-02-24 06:45:25,423:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-02-24 06:45:25,425:INFO:setup() successfully completed in 1.93s...............
2025-02-24 06:45:25,433:INFO:Initializing compare_models()
2025-02-24 06:45:25,433:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-24 06:45:25,433:INFO:Checking exceptions
2025-02-24 06:45:25,440:INFO:Preparing display monitor
2025-02-24 06:45:25,516:INFO:Initializing Logistic Regression
2025-02-24 06:45:25,516:INFO:Total runtime is 2.4596850077311197e-06 minutes
2025-02-24 06:45:25,525:INFO:SubProcess create_model() called ==================================
2025-02-24 06:45:25,525:INFO:Initializing create_model()
2025-02-24 06:45:25,525:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa5fe9cf850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:45:25,525:INFO:Checking exceptions
2025-02-24 06:45:25,525:INFO:Importing libraries
2025-02-24 06:45:25,525:INFO:Copying training dataset
2025-02-24 06:45:25,537:INFO:Defining folds
2025-02-24 06:45:25,537:INFO:Declaring metric variables
2025-02-24 06:45:25,545:INFO:Importing untrained model
2025-02-24 06:45:25,557:INFO:Logistic Regression Imported successfully
2025-02-24 06:45:25,591:INFO:Starting cross validation
2025-02-24 06:45:25,597:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:45:33,024:WARNING:/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2025-02-24 06:45:33,329:WARNING:/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2025-02-24 06:45:36,556:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-24 06:45:36,606:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:36,609:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:36,621:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:36,623:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:36,626:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:36,637:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-24 06:45:36,706:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:36,709:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:36,737:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:36,740:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:36,753:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:39,782:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-24 06:45:39,871:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:39,874:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:39,885:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:39,887:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:39,894:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:40,620:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-24 06:45:40,744:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:40,749:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:40,768:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:40,770:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:40,788:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:42,721:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-24 06:45:42,790:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:42,793:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:42,798:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:42,800:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:42,802:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:43,486:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-24 06:45:43,537:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:43,539:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:43,544:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:43,547:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:43,549:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:45,051:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-24 06:45:45,115:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:45,117:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:45,129:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:45,132:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:45,141:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:46,112:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-24 06:45:46,165:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:46,167:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:46,172:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:46,175:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:46,177:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:46,971:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-24 06:45:47,016:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:47,018:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:47,022:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:47,025:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:47,027:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:47,524:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-24 06:45:47,559:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:47,560:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:47,563:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:47,565:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:47,567:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:47,582:INFO:Calculating mean and std
2025-02-24 06:45:47,584:INFO:Creating metrics dataframe
2025-02-24 06:45:47,587:INFO:Uploading results into container
2025-02-24 06:45:47,587:INFO:Uploading model into container now
2025-02-24 06:45:47,588:INFO:_master_model_container: 1
2025-02-24 06:45:47,588:INFO:_display_container: 2
2025-02-24 06:45:47,588:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4169, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-24 06:45:47,588:INFO:create_model() successfully completed......................................
2025-02-24 06:45:47,799:INFO:SubProcess create_model() end ==================================
2025-02-24 06:45:47,799:INFO:Creating metrics dataframe
2025-02-24 06:45:47,807:INFO:Initializing K Neighbors Classifier
2025-02-24 06:45:47,807:INFO:Total runtime is 0.3715174357096354 minutes
2025-02-24 06:45:47,815:INFO:SubProcess create_model() called ==================================
2025-02-24 06:45:47,815:INFO:Initializing create_model()
2025-02-24 06:45:47,815:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa5fe9cf850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:45:47,815:INFO:Checking exceptions
2025-02-24 06:45:47,815:INFO:Importing libraries
2025-02-24 06:45:47,816:INFO:Copying training dataset
2025-02-24 06:45:47,823:INFO:Defining folds
2025-02-24 06:45:47,823:INFO:Declaring metric variables
2025-02-24 06:45:47,831:INFO:Importing untrained model
2025-02-24 06:45:47,840:INFO:K Neighbors Classifier Imported successfully
2025-02-24 06:45:47,853:INFO:Starting cross validation
2025-02-24 06:45:47,856:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:45:48,117:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:48,122:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:48,125:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:48,126:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:48,128:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:48,132:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:48,134:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:48,137:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:48,373:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:48,378:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:48,381:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:48,384:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:48,387:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:48,392:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:48,395:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:48,401:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:48,672:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:48,678:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:48,680:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:48,682:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:48,683:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:48,687:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:48,689:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:48,692:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:48,931:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:48,936:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:48,939:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:48,939:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:48,941:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:48,944:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:48,947:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:48,953:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:49,188:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:49,192:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:49,195:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:49,198:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:49,205:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:49,209:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:49,211:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:49,213:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:49,220:INFO:Calculating mean and std
2025-02-24 06:45:49,221:INFO:Creating metrics dataframe
2025-02-24 06:45:49,223:INFO:Uploading results into container
2025-02-24 06:45:49,223:INFO:Uploading model into container now
2025-02-24 06:45:49,224:INFO:_master_model_container: 2
2025-02-24 06:45:49,224:INFO:_display_container: 2
2025-02-24 06:45:49,224:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-02-24 06:45:49,224:INFO:create_model() successfully completed......................................
2025-02-24 06:45:49,406:INFO:SubProcess create_model() end ==================================
2025-02-24 06:45:49,407:INFO:Creating metrics dataframe
2025-02-24 06:45:49,415:INFO:Initializing Naive Bayes
2025-02-24 06:45:49,415:INFO:Total runtime is 0.39831697940826416 minutes
2025-02-24 06:45:49,429:INFO:SubProcess create_model() called ==================================
2025-02-24 06:45:49,430:INFO:Initializing create_model()
2025-02-24 06:45:49,431:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa5fe9cf850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:45:49,431:INFO:Checking exceptions
2025-02-24 06:45:49,431:INFO:Importing libraries
2025-02-24 06:45:49,431:INFO:Copying training dataset
2025-02-24 06:45:49,441:INFO:Defining folds
2025-02-24 06:45:49,441:INFO:Declaring metric variables
2025-02-24 06:45:49,450:INFO:Importing untrained model
2025-02-24 06:45:49,459:INFO:Naive Bayes Imported successfully
2025-02-24 06:45:49,473:INFO:Starting cross validation
2025-02-24 06:45:49,476:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:45:49,717:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:49,723:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:49,728:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:49,753:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:49,758:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:49,766:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:49,956:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:49,961:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:49,965:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:49,978:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:49,985:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:49,990:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:50,195:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:50,200:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:50,206:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:50,209:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:50,221:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:50,227:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:50,422:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:50,427:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:50,432:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:50,445:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:50,450:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:50,455:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:50,655:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:50,661:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:50,667:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:50,691:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:50,695:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:50,701:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:50,711:INFO:Calculating mean and std
2025-02-24 06:45:50,712:INFO:Creating metrics dataframe
2025-02-24 06:45:50,715:INFO:Uploading results into container
2025-02-24 06:45:50,717:INFO:Uploading model into container now
2025-02-24 06:45:50,717:INFO:_master_model_container: 3
2025-02-24 06:45:50,718:INFO:_display_container: 2
2025-02-24 06:45:50,718:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-02-24 06:45:50,718:INFO:create_model() successfully completed......................................
2025-02-24 06:45:50,904:INFO:SubProcess create_model() end ==================================
2025-02-24 06:45:50,904:INFO:Creating metrics dataframe
2025-02-24 06:45:50,911:INFO:Initializing Decision Tree Classifier
2025-02-24 06:45:50,911:INFO:Total runtime is 0.42324507236480713 minutes
2025-02-24 06:45:50,917:INFO:SubProcess create_model() called ==================================
2025-02-24 06:45:50,918:INFO:Initializing create_model()
2025-02-24 06:45:50,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa5fe9cf850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:45:50,918:INFO:Checking exceptions
2025-02-24 06:45:50,918:INFO:Importing libraries
2025-02-24 06:45:50,918:INFO:Copying training dataset
2025-02-24 06:45:50,925:INFO:Defining folds
2025-02-24 06:45:50,925:INFO:Declaring metric variables
2025-02-24 06:45:50,932:INFO:Importing untrained model
2025-02-24 06:45:50,945:INFO:Decision Tree Classifier Imported successfully
2025-02-24 06:45:50,959:INFO:Starting cross validation
2025-02-24 06:45:50,963:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:45:51,216:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:51,221:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:51,222:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:51,226:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:51,227:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:51,233:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:51,470:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:51,475:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:51,475:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:51,479:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:51,480:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:51,484:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:51,738:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:51,743:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:51,743:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:51,748:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:51,748:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:51,753:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:51,997:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:52,003:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:52,008:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:52,008:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:52,013:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:52,022:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:52,243:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:52,248:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:52,253:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:52,260:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:52,263:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:52,266:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:52,277:INFO:Calculating mean and std
2025-02-24 06:45:52,278:INFO:Creating metrics dataframe
2025-02-24 06:45:52,280:INFO:Uploading results into container
2025-02-24 06:45:52,280:INFO:Uploading model into container now
2025-02-24 06:45:52,281:INFO:_master_model_container: 4
2025-02-24 06:45:52,281:INFO:_display_container: 2
2025-02-24 06:45:52,281:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=4169, splitter='best')
2025-02-24 06:45:52,281:INFO:create_model() successfully completed......................................
2025-02-24 06:45:52,441:INFO:SubProcess create_model() end ==================================
2025-02-24 06:45:52,442:INFO:Creating metrics dataframe
2025-02-24 06:45:52,452:INFO:Initializing SVM - Linear Kernel
2025-02-24 06:45:52,452:INFO:Total runtime is 0.44893128871917726 minutes
2025-02-24 06:45:52,458:INFO:SubProcess create_model() called ==================================
2025-02-24 06:45:52,459:INFO:Initializing create_model()
2025-02-24 06:45:52,459:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa5fe9cf850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:45:52,459:INFO:Checking exceptions
2025-02-24 06:45:52,459:INFO:Importing libraries
2025-02-24 06:45:52,459:INFO:Copying training dataset
2025-02-24 06:45:52,468:INFO:Defining folds
2025-02-24 06:45:52,468:INFO:Declaring metric variables
2025-02-24 06:45:52,474:INFO:Importing untrained model
2025-02-24 06:45:52,482:INFO:SVM - Linear Kernel Imported successfully
2025-02-24 06:45:52,495:INFO:Starting cross validation
2025-02-24 06:45:52,499:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:45:52,806:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:52,808:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:52,812:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:52,814:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:52,816:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:52,864:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:52,866:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:52,872:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:52,875:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:52,877:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:53,114:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:53,116:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:53,121:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:53,123:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:53,125:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:53,208:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:53,210:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:53,215:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:53,218:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:53,221:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:53,473:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:53,475:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:53,478:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:53,480:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:53,481:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:53,533:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:53,535:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:53,540:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:53,543:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:53,545:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:53,837:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:53,840:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:53,846:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:53,849:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:53,852:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:53,871:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:53,873:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:53,878:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:53,881:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:53,883:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:54,189:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:54,192:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:54,196:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:54,197:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:54,198:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:54,199:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:54,202:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:54,203:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:54,205:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:54,208:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:54,221:INFO:Calculating mean and std
2025-02-24 06:45:54,222:INFO:Creating metrics dataframe
2025-02-24 06:45:54,225:INFO:Uploading results into container
2025-02-24 06:45:54,226:INFO:Uploading model into container now
2025-02-24 06:45:54,226:INFO:_master_model_container: 5
2025-02-24 06:45:54,226:INFO:_display_container: 2
2025-02-24 06:45:54,227:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4169, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-02-24 06:45:54,227:INFO:create_model() successfully completed......................................
2025-02-24 06:45:54,422:INFO:SubProcess create_model() end ==================================
2025-02-24 06:45:54,423:INFO:Creating metrics dataframe
2025-02-24 06:45:54,433:INFO:Initializing Ridge Classifier
2025-02-24 06:45:54,433:INFO:Total runtime is 0.4819517334302267 minutes
2025-02-24 06:45:54,440:INFO:SubProcess create_model() called ==================================
2025-02-24 06:45:54,440:INFO:Initializing create_model()
2025-02-24 06:45:54,440:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa5fe9cf850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:45:54,440:INFO:Checking exceptions
2025-02-24 06:45:54,440:INFO:Importing libraries
2025-02-24 06:45:54,440:INFO:Copying training dataset
2025-02-24 06:45:54,448:INFO:Defining folds
2025-02-24 06:45:54,448:INFO:Declaring metric variables
2025-02-24 06:45:54,456:INFO:Importing untrained model
2025-02-24 06:45:54,465:INFO:Ridge Classifier Imported successfully
2025-02-24 06:45:54,479:INFO:Starting cross validation
2025-02-24 06:45:54,483:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:45:54,682:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:54,685:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:54,690:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:54,693:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:54,696:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:54,705:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:54,707:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:54,722:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:54,730:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:54,740:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:54,921:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:54,924:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:54,929:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:54,932:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:54,934:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:54,952:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:54,954:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:54,959:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:54,962:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:54,965:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:55,142:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:55,144:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:55,149:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:55,152:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:55,154:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:55,174:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:55,178:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:55,183:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:55,186:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:55,188:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:55,374:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:55,378:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:55,384:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:55,386:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:55,389:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:55,401:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:55,403:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:55,408:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:55,411:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:55,417:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:55,648:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:55,650:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:55,655:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:55,658:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:55,660:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:55,673:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:45:55,676:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:55,681:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:55,684:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:55,689:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:55,708:INFO:Calculating mean and std
2025-02-24 06:45:55,710:INFO:Creating metrics dataframe
2025-02-24 06:45:55,713:INFO:Uploading results into container
2025-02-24 06:45:55,713:INFO:Uploading model into container now
2025-02-24 06:45:55,714:INFO:_master_model_container: 6
2025-02-24 06:45:55,714:INFO:_display_container: 2
2025-02-24 06:45:55,714:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4169, solver='auto',
                tol=0.0001)
2025-02-24 06:45:55,714:INFO:create_model() successfully completed......................................
2025-02-24 06:45:55,947:INFO:SubProcess create_model() end ==================================
2025-02-24 06:45:55,948:INFO:Creating metrics dataframe
2025-02-24 06:45:55,956:INFO:Initializing Random Forest Classifier
2025-02-24 06:45:55,957:INFO:Total runtime is 0.5073376099268596 minutes
2025-02-24 06:45:55,963:INFO:SubProcess create_model() called ==================================
2025-02-24 06:45:55,963:INFO:Initializing create_model()
2025-02-24 06:45:55,963:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa5fe9cf850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:45:55,963:INFO:Checking exceptions
2025-02-24 06:45:55,963:INFO:Importing libraries
2025-02-24 06:45:55,963:INFO:Copying training dataset
2025-02-24 06:45:55,979:INFO:Defining folds
2025-02-24 06:45:55,979:INFO:Declaring metric variables
2025-02-24 06:45:55,986:INFO:Importing untrained model
2025-02-24 06:45:55,995:INFO:Random Forest Classifier Imported successfully
2025-02-24 06:45:56,009:INFO:Starting cross validation
2025-02-24 06:45:56,011:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:45:57,467:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:57,473:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:57,475:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:57,478:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:57,577:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:57,582:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:57,585:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:57,587:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:58,460:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:58,465:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:58,468:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:58,471:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:58,549:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:58,554:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:58,557:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:58,560:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:59,419:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:59,425:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:59,427:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:59,430:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:59,564:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:59,569:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:45:59,572:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:45:59,575:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:00,399:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:00,405:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:00,407:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:00,410:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:00,529:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:00,534:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:00,539:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:01,349:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:01,354:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:01,356:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:01,359:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:01,458:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:01,462:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:01,463:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:01,465:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:01,480:INFO:Calculating mean and std
2025-02-24 06:46:01,481:INFO:Creating metrics dataframe
2025-02-24 06:46:01,483:INFO:Uploading results into container
2025-02-24 06:46:01,484:INFO:Uploading model into container now
2025-02-24 06:46:01,484:INFO:_master_model_container: 7
2025-02-24 06:46:01,484:INFO:_display_container: 2
2025-02-24 06:46:01,485:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4169, verbose=0,
                       warm_start=False)
2025-02-24 06:46:01,485:INFO:create_model() successfully completed......................................
2025-02-24 06:46:01,656:INFO:SubProcess create_model() end ==================================
2025-02-24 06:46:01,656:INFO:Creating metrics dataframe
2025-02-24 06:46:01,669:INFO:Initializing Quadratic Discriminant Analysis
2025-02-24 06:46:01,669:INFO:Total runtime is 0.6025413036346436 minutes
2025-02-24 06:46:01,676:INFO:SubProcess create_model() called ==================================
2025-02-24 06:46:01,676:INFO:Initializing create_model()
2025-02-24 06:46:01,676:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa5fe9cf850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:46:01,676:INFO:Checking exceptions
2025-02-24 06:46:01,676:INFO:Importing libraries
2025-02-24 06:46:01,677:INFO:Copying training dataset
2025-02-24 06:46:01,686:INFO:Defining folds
2025-02-24 06:46:01,686:INFO:Declaring metric variables
2025-02-24 06:46:01,699:INFO:Importing untrained model
2025-02-24 06:46:01,710:INFO:Quadratic Discriminant Analysis Imported successfully
2025-02-24 06:46:01,729:INFO:Starting cross validation
2025-02-24 06:46:01,733:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:46:01,914:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-02-24 06:46:01,914:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-02-24 06:46:01,976:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:01,979:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:01,981:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:01,983:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:01,983:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:01,986:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:01,988:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:01,988:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:01,990:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:01,995:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,150:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-02-24 06:46:02,156:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-02-24 06:46:02,216:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:02,219:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,222:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:02,224:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,224:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,226:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:02,229:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,230:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,233:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:02,235:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,379:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-02-24 06:46:02,379:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-02-24 06:46:02,439:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:02,440:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:02,441:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,442:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,446:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,447:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,448:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:02,450:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:02,451:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,452:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,601:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-02-24 06:46:02,625:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-02-24 06:46:02,671:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:02,673:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,678:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,682:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:02,685:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,698:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:02,700:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,706:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,709:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:02,712:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,838:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-02-24 06:46:02,872:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-02-24 06:46:02,905:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:02,907:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,912:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,915:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:02,918:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,933:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:02,934:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,937:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,938:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:02,940:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:02,950:INFO:Calculating mean and std
2025-02-24 06:46:02,951:INFO:Creating metrics dataframe
2025-02-24 06:46:02,953:INFO:Uploading results into container
2025-02-24 06:46:02,954:INFO:Uploading model into container now
2025-02-24 06:46:02,954:INFO:_master_model_container: 8
2025-02-24 06:46:02,954:INFO:_display_container: 2
2025-02-24 06:46:02,955:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-02-24 06:46:02,955:INFO:create_model() successfully completed......................................
2025-02-24 06:46:03,159:INFO:SubProcess create_model() end ==================================
2025-02-24 06:46:03,160:INFO:Creating metrics dataframe
2025-02-24 06:46:03,171:INFO:Initializing Ada Boost Classifier
2025-02-24 06:46:03,173:INFO:Total runtime is 0.6276082277297974 minutes
2025-02-24 06:46:03,180:INFO:SubProcess create_model() called ==================================
2025-02-24 06:46:03,181:INFO:Initializing create_model()
2025-02-24 06:46:03,181:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa5fe9cf850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:46:03,181:INFO:Checking exceptions
2025-02-24 06:46:03,181:INFO:Importing libraries
2025-02-24 06:46:03,181:INFO:Copying training dataset
2025-02-24 06:46:03,189:INFO:Defining folds
2025-02-24 06:46:03,189:INFO:Declaring metric variables
2025-02-24 06:46:03,196:INFO:Importing untrained model
2025-02-24 06:46:03,205:INFO:Ada Boost Classifier Imported successfully
2025-02-24 06:46:03,219:INFO:Starting cross validation
2025-02-24 06:46:03,222:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:46:03,371:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-02-24 06:46:03,375:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-02-24 06:46:03,700:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:03,703:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:03,708:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:03,711:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:03,714:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:03,716:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:03,718:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:03,725:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:03,731:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:03,734:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:03,863:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-02-24 06:46:03,882:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-02-24 06:46:04,194:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:04,196:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:04,201:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:04,203:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:04,203:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:04,206:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:04,206:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:04,211:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:04,213:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:04,216:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:04,365:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-02-24 06:46:04,367:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-02-24 06:46:04,692:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:04,692:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:04,694:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:04,694:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:04,699:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:04,699:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:04,701:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:04,701:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:04,704:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:04,704:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:04,860:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-02-24 06:46:04,869:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-02-24 06:46:05,198:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:05,201:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:05,206:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:05,209:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:05,211:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:05,211:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:05,213:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:05,219:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:05,222:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:05,228:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:05,358:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-02-24 06:46:05,373:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-02-24 06:46:05,680:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:05,683:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:05,688:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:05,691:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:05,694:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:05,697:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:05,699:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:05,704:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:05,707:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:05,715:INFO:Calculating mean and std
2025-02-24 06:46:05,716:INFO:Creating metrics dataframe
2025-02-24 06:46:05,718:INFO:Uploading results into container
2025-02-24 06:46:05,719:INFO:Uploading model into container now
2025-02-24 06:46:05,719:INFO:_master_model_container: 9
2025-02-24 06:46:05,719:INFO:_display_container: 2
2025-02-24 06:46:05,721:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4169)
2025-02-24 06:46:05,721:INFO:create_model() successfully completed......................................
2025-02-24 06:46:05,913:INFO:SubProcess create_model() end ==================================
2025-02-24 06:46:05,913:INFO:Creating metrics dataframe
2025-02-24 06:46:05,921:INFO:Initializing Gradient Boosting Classifier
2025-02-24 06:46:05,921:INFO:Total runtime is 0.6734137018521628 minutes
2025-02-24 06:46:05,927:INFO:SubProcess create_model() called ==================================
2025-02-24 06:46:05,928:INFO:Initializing create_model()
2025-02-24 06:46:05,928:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa5fe9cf850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:46:05,928:INFO:Checking exceptions
2025-02-24 06:46:05,928:INFO:Importing libraries
2025-02-24 06:46:05,928:INFO:Copying training dataset
2025-02-24 06:46:05,936:INFO:Defining folds
2025-02-24 06:46:05,937:INFO:Declaring metric variables
2025-02-24 06:46:05,943:INFO:Importing untrained model
2025-02-24 06:46:05,952:INFO:Gradient Boosting Classifier Imported successfully
2025-02-24 06:46:05,966:INFO:Starting cross validation
2025-02-24 06:46:05,968:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:46:14,567:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:14,569:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:14,574:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:14,576:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:14,579:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:14,703:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:14,705:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:14,710:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:14,713:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:14,716:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:23,293:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:23,296:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:23,303:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:23,307:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:23,569:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:23,571:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:23,577:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:23,580:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:23,582:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:31,215:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:31,218:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:31,222:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:31,225:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:31,227:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:32,249:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:32,251:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:32,270:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:32,273:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:32,275:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:40,751:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:40,754:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:40,758:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:40,763:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:41,185:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:41,187:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:41,192:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:41,194:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:41,197:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:49,450:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:49,452:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:49,457:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:49,459:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:49,461:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:49,758:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:49,760:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:49,763:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:49,766:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:49,781:INFO:Calculating mean and std
2025-02-24 06:46:49,783:INFO:Creating metrics dataframe
2025-02-24 06:46:49,785:INFO:Uploading results into container
2025-02-24 06:46:49,785:INFO:Uploading model into container now
2025-02-24 06:46:49,786:INFO:_master_model_container: 10
2025-02-24 06:46:49,786:INFO:_display_container: 2
2025-02-24 06:46:49,786:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4169, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-02-24 06:46:49,786:INFO:create_model() successfully completed......................................
2025-02-24 06:46:49,960:INFO:SubProcess create_model() end ==================================
2025-02-24 06:46:49,960:INFO:Creating metrics dataframe
2025-02-24 06:46:49,971:INFO:Initializing Linear Discriminant Analysis
2025-02-24 06:46:49,972:INFO:Total runtime is 1.4075880567232768 minutes
2025-02-24 06:46:49,978:INFO:SubProcess create_model() called ==================================
2025-02-24 06:46:49,978:INFO:Initializing create_model()
2025-02-24 06:46:49,978:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa5fe9cf850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:46:49,978:INFO:Checking exceptions
2025-02-24 06:46:49,978:INFO:Importing libraries
2025-02-24 06:46:49,978:INFO:Copying training dataset
2025-02-24 06:46:49,986:INFO:Defining folds
2025-02-24 06:46:49,986:INFO:Declaring metric variables
2025-02-24 06:46:49,992:INFO:Importing untrained model
2025-02-24 06:46:50,002:INFO:Linear Discriminant Analysis Imported successfully
2025-02-24 06:46:50,016:INFO:Starting cross validation
2025-02-24 06:46:50,019:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:46:50,236:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:50,239:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:50,242:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:50,244:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:50,244:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:50,246:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:50,248:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:50,249:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:50,251:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:50,253:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:50,472:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:50,474:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:50,475:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:50,477:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:50,480:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:50,482:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:50,483:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:50,485:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:50,486:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:50,487:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:50,705:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:50,708:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:50,713:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:50,716:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:50,719:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:50,738:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:50,740:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:50,745:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:50,748:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:50,751:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:50,944:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:50,947:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:50,952:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:50,955:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:50,957:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:50,961:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:50,963:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:50,968:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:50,971:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:50,973:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:51,169:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:51,172:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:51,178:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:51,180:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:46:51,180:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:51,182:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:51,183:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:51,187:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:51,190:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:51,192:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:51,198:INFO:Calculating mean and std
2025-02-24 06:46:51,199:INFO:Creating metrics dataframe
2025-02-24 06:46:51,200:INFO:Uploading results into container
2025-02-24 06:46:51,201:INFO:Uploading model into container now
2025-02-24 06:46:51,201:INFO:_master_model_container: 11
2025-02-24 06:46:51,201:INFO:_display_container: 2
2025-02-24 06:46:51,201:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-02-24 06:46:51,202:INFO:create_model() successfully completed......................................
2025-02-24 06:46:51,381:INFO:SubProcess create_model() end ==================================
2025-02-24 06:46:51,382:INFO:Creating metrics dataframe
2025-02-24 06:46:51,391:INFO:Initializing Extra Trees Classifier
2025-02-24 06:46:51,391:INFO:Total runtime is 1.4312510331471762 minutes
2025-02-24 06:46:51,397:INFO:SubProcess create_model() called ==================================
2025-02-24 06:46:51,397:INFO:Initializing create_model()
2025-02-24 06:46:51,397:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa5fe9cf850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:46:51,397:INFO:Checking exceptions
2025-02-24 06:46:51,397:INFO:Importing libraries
2025-02-24 06:46:51,397:INFO:Copying training dataset
2025-02-24 06:46:51,405:INFO:Defining folds
2025-02-24 06:46:51,406:INFO:Declaring metric variables
2025-02-24 06:46:51,416:INFO:Importing untrained model
2025-02-24 06:46:51,425:INFO:Extra Trees Classifier Imported successfully
2025-02-24 06:46:51,439:INFO:Starting cross validation
2025-02-24 06:46:51,442:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:46:52,342:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:52,347:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:52,350:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:52,352:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:52,374:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:52,380:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:52,388:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:53,268:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:53,273:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:53,275:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:53,278:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:53,280:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:53,286:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:54,187:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:54,187:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:54,192:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:54,192:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:54,194:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:54,196:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:54,196:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:55,104:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:55,110:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:55,110:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:55,115:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:55,115:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:55,118:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:55,123:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:56,547:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:56,552:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:56,561:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:56,590:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:56,598:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:56,603:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:56,618:INFO:Calculating mean and std
2025-02-24 06:46:56,620:INFO:Creating metrics dataframe
2025-02-24 06:46:56,624:INFO:Uploading results into container
2025-02-24 06:46:56,625:INFO:Uploading model into container now
2025-02-24 06:46:56,626:INFO:_master_model_container: 12
2025-02-24 06:46:56,626:INFO:_display_container: 2
2025-02-24 06:46:56,626:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=4169, verbose=0,
                     warm_start=False)
2025-02-24 06:46:56,627:INFO:create_model() successfully completed......................................
2025-02-24 06:46:56,843:INFO:SubProcess create_model() end ==================================
2025-02-24 06:46:56,843:INFO:Creating metrics dataframe
2025-02-24 06:46:56,856:INFO:Initializing Extreme Gradient Boosting
2025-02-24 06:46:56,856:INFO:Total runtime is 1.5223365783691407 minutes
2025-02-24 06:46:56,864:INFO:SubProcess create_model() called ==================================
2025-02-24 06:46:56,865:INFO:Initializing create_model()
2025-02-24 06:46:56,865:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa5fe9cf850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:46:56,865:INFO:Checking exceptions
2025-02-24 06:46:56,865:INFO:Importing libraries
2025-02-24 06:46:56,865:INFO:Copying training dataset
2025-02-24 06:46:56,876:INFO:Defining folds
2025-02-24 06:46:56,876:INFO:Declaring metric variables
2025-02-24 06:46:56,888:INFO:Importing untrained model
2025-02-24 06:46:56,898:INFO:Extreme Gradient Boosting Imported successfully
2025-02-24 06:46:56,913:INFO:Starting cross validation
2025-02-24 06:46:56,916:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:46:58,572:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:58,574:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:58,577:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:58,579:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:58,579:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:58,581:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:46:58,582:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:46:58,584:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:00,152:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:00,156:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:00,159:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:47:00,162:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:00,170:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:00,175:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:00,177:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:47:00,182:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:01,752:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:01,757:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:01,759:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:47:01,762:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:01,785:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:01,791:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:01,793:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:47:01,796:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:03,352:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:03,358:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:03,361:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:47:03,363:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:03,467:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:03,475:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:03,480:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:04,960:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:04,965:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:04,969:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:05,000:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:05,003:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:05,007:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:05,017:INFO:Calculating mean and std
2025-02-24 06:47:05,018:INFO:Creating metrics dataframe
2025-02-24 06:47:05,020:INFO:Uploading results into container
2025-02-24 06:47:05,021:INFO:Uploading model into container now
2025-02-24 06:47:05,021:INFO:_master_model_container: 13
2025-02-24 06:47:05,021:INFO:_display_container: 2
2025-02-24 06:47:05,022:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-02-24 06:47:05,022:INFO:create_model() successfully completed......................................
2025-02-24 06:47:05,202:INFO:SubProcess create_model() end ==================================
2025-02-24 06:47:05,202:INFO:Creating metrics dataframe
2025-02-24 06:47:05,213:INFO:Initializing Light Gradient Boosting Machine
2025-02-24 06:47:05,213:INFO:Total runtime is 1.661617124080658 minutes
2025-02-24 06:47:05,220:INFO:SubProcess create_model() called ==================================
2025-02-24 06:47:05,220:INFO:Initializing create_model()
2025-02-24 06:47:05,220:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa5fe9cf850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:47:05,220:INFO:Checking exceptions
2025-02-24 06:47:05,220:INFO:Importing libraries
2025-02-24 06:47:05,220:INFO:Copying training dataset
2025-02-24 06:47:05,228:INFO:Defining folds
2025-02-24 06:47:05,228:INFO:Declaring metric variables
2025-02-24 06:47:05,236:INFO:Importing untrained model
2025-02-24 06:47:05,245:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-24 06:47:05,257:INFO:Starting cross validation
2025-02-24 06:47:05,260:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:47:16,560:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:16,565:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:16,567:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:47:16,569:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:16,790:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:16,794:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:16,795:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:47:16,797:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:27,586:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:27,590:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:27,592:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:47:27,594:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:30,260:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:30,270:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:30,276:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:47:30,281:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:37,719:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:37,723:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:37,725:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:47:37,727:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:39,820:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:39,824:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:39,825:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:47:39,827:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:48,842:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:48,848:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:48,850:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:47:48,853:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:48,977:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:48,982:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:47:48,985:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:47:48,988:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:02,307:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:02,312:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:02,314:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:02,317:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:02,345:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:02,349:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:02,350:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:02,352:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:02,365:INFO:Calculating mean and std
2025-02-24 06:48:02,366:INFO:Creating metrics dataframe
2025-02-24 06:48:02,368:INFO:Uploading results into container
2025-02-24 06:48:02,368:INFO:Uploading model into container now
2025-02-24 06:48:02,369:INFO:_master_model_container: 14
2025-02-24 06:48:02,370:INFO:_display_container: 2
2025-02-24 06:48:02,370:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4169, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-24 06:48:02,370:INFO:create_model() successfully completed......................................
2025-02-24 06:48:02,553:INFO:SubProcess create_model() end ==================================
2025-02-24 06:48:02,553:INFO:Creating metrics dataframe
2025-02-24 06:48:02,564:INFO:Initializing Dummy Classifier
2025-02-24 06:48:02,564:INFO:Total runtime is 2.6174583395322166 minutes
2025-02-24 06:48:02,574:INFO:SubProcess create_model() called ==================================
2025-02-24 06:48:02,574:INFO:Initializing create_model()
2025-02-24 06:48:02,575:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa5fe9cf850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:48:02,575:INFO:Checking exceptions
2025-02-24 06:48:02,575:INFO:Importing libraries
2025-02-24 06:48:02,575:INFO:Copying training dataset
2025-02-24 06:48:02,584:INFO:Defining folds
2025-02-24 06:48:02,585:INFO:Declaring metric variables
2025-02-24 06:48:02,592:INFO:Importing untrained model
2025-02-24 06:48:02,602:INFO:Dummy Classifier Imported successfully
2025-02-24 06:48:02,618:INFO:Starting cross validation
2025-02-24 06:48:02,621:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:48:02,863:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:02,865:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:02,868:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:02,870:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:02,870:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:02,874:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:02,874:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:02,878:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,106:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,111:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,113:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:03,116:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,122:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,128:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,130:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:03,133:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,332:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,332:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,337:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,337:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,340:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:03,340:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:03,342:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,342:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,553:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,553:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,558:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,558:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,560:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:03,560:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:03,562:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,563:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,787:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,790:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,792:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,795:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,795:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:03,797:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:03,797:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,800:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:03,816:INFO:Calculating mean and std
2025-02-24 06:48:03,818:INFO:Creating metrics dataframe
2025-02-24 06:48:03,822:INFO:Uploading results into container
2025-02-24 06:48:03,823:INFO:Uploading model into container now
2025-02-24 06:48:03,824:INFO:_master_model_container: 15
2025-02-24 06:48:03,824:INFO:_display_container: 2
2025-02-24 06:48:03,824:INFO:DummyClassifier(constant=None, random_state=4169, strategy='prior')
2025-02-24 06:48:03,824:INFO:create_model() successfully completed......................................
2025-02-24 06:48:04,046:INFO:SubProcess create_model() end ==================================
2025-02-24 06:48:04,046:INFO:Creating metrics dataframe
2025-02-24 06:48:04,078:INFO:Initializing create_model()
2025-02-24 06:48:04,078:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4169, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:48:04,078:INFO:Checking exceptions
2025-02-24 06:48:04,080:INFO:Importing libraries
2025-02-24 06:48:04,080:INFO:Copying training dataset
2025-02-24 06:48:04,091:INFO:Defining folds
2025-02-24 06:48:04,091:INFO:Declaring metric variables
2025-02-24 06:48:04,091:INFO:Importing untrained model
2025-02-24 06:48:04,091:INFO:Declaring custom model
2025-02-24 06:48:04,092:INFO:Ridge Classifier Imported successfully
2025-02-24 06:48:04,095:INFO:Cross validation set to False
2025-02-24 06:48:04,096:INFO:Fitting Model
2025-02-24 06:48:04,198:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4169, solver='auto',
                tol=0.0001)
2025-02-24 06:48:04,198:INFO:create_model() successfully completed......................................
2025-02-24 06:48:04,455:INFO:_master_model_container: 15
2025-02-24 06:48:04,455:INFO:_display_container: 2
2025-02-24 06:48:04,455:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4169, solver='auto',
                tol=0.0001)
2025-02-24 06:48:04,455:INFO:compare_models() successfully completed......................................
2025-02-24 06:48:04,462:INFO:Initializing compare_models()
2025-02-24 06:48:04,463:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa6012c0890>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fa6012c0890>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-02-24 06:48:04,463:INFO:Checking exceptions
2025-02-24 06:48:04,468:INFO:Preparing display monitor
2025-02-24 06:48:04,511:INFO:Initializing Logistic Regression
2025-02-24 06:48:04,511:INFO:Total runtime is 2.8491020202636717e-06 minutes
2025-02-24 06:48:04,518:INFO:SubProcess create_model() called ==================================
2025-02-24 06:48:04,518:INFO:Initializing create_model()
2025-02-24 06:48:04,518:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa6012c0890>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa60013e310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:48:04,518:INFO:Checking exceptions
2025-02-24 06:48:04,518:INFO:Importing libraries
2025-02-24 06:48:04,518:INFO:Copying training dataset
2025-02-24 06:48:04,525:INFO:Defining folds
2025-02-24 06:48:04,525:INFO:Declaring metric variables
2025-02-24 06:48:04,531:INFO:Importing untrained model
2025-02-24 06:48:04,536:INFO:Logistic Regression Imported successfully
2025-02-24 06:48:04,549:INFO:Starting cross validation
2025-02-24 06:48:04,552:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:48:06,963:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-24 06:48:07,010:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:07,013:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:07,018:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:07,020:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:07,023:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:07,169:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-24 06:48:07,219:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:07,222:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:07,226:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:07,229:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:07,231:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:08,742:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-24 06:48:08,796:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:08,798:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:08,803:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:08,805:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:08,808:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:08,916:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-24 06:48:08,971:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:08,973:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:08,978:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:08,980:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:08,983:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:10,526:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-24 06:48:10,576:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:10,578:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:10,583:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:10,585:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:10,588:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:10,692:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-24 06:48:10,745:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:10,747:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:10,752:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:10,754:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:10,756:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:12,234:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-24 06:48:12,296:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:12,305:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:12,309:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:12,312:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:12,314:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:12,423:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-24 06:48:12,473:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:12,475:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:12,480:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:12,482:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:12,484:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:13,994:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-24 06:48:14,042:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:14,044:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:14,049:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:14,052:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:14,055:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:14,136:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-02-24 06:48:14,175:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:14,177:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:14,180:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:14,182:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:14,183:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:14,192:INFO:Calculating mean and std
2025-02-24 06:48:14,194:INFO:Creating metrics dataframe
2025-02-24 06:48:14,196:INFO:Uploading results into container
2025-02-24 06:48:14,196:INFO:Uploading model into container now
2025-02-24 06:48:14,197:INFO:_master_model_container: 1
2025-02-24 06:48:14,197:INFO:_display_container: 2
2025-02-24 06:48:14,197:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-02-24 06:48:14,197:INFO:create_model() successfully completed......................................
2025-02-24 06:48:14,420:INFO:SubProcess create_model() end ==================================
2025-02-24 06:48:14,421:INFO:Creating metrics dataframe
2025-02-24 06:48:14,434:INFO:Initializing K Neighbors Classifier
2025-02-24 06:48:14,434:INFO:Total runtime is 0.16538657347361246 minutes
2025-02-24 06:48:14,446:INFO:SubProcess create_model() called ==================================
2025-02-24 06:48:14,446:INFO:Initializing create_model()
2025-02-24 06:48:14,446:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa6012c0890>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa60013e310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:48:14,447:INFO:Checking exceptions
2025-02-24 06:48:14,447:INFO:Importing libraries
2025-02-24 06:48:14,447:INFO:Copying training dataset
2025-02-24 06:48:14,457:INFO:Defining folds
2025-02-24 06:48:14,458:INFO:Declaring metric variables
2025-02-24 06:48:14,468:INFO:Importing untrained model
2025-02-24 06:48:14,477:INFO:K Neighbors Classifier Imported successfully
2025-02-24 06:48:14,494:INFO:Starting cross validation
2025-02-24 06:48:14,498:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:48:14,745:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:14,750:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:14,752:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:14,755:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:14,763:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:14,768:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:14,774:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:14,776:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:14,999:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,003:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,006:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:15,008:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,016:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,022:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,025:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:15,028:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,253:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,258:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,261:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:15,263:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,268:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,274:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,277:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:15,279:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,531:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,536:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,536:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,539:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:15,541:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,541:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,543:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:15,545:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,774:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,779:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,782:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:15,784:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,784:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,789:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,792:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:15,794:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:15,805:INFO:Calculating mean and std
2025-02-24 06:48:15,806:INFO:Creating metrics dataframe
2025-02-24 06:48:15,809:INFO:Uploading results into container
2025-02-24 06:48:15,809:INFO:Uploading model into container now
2025-02-24 06:48:15,810:INFO:_master_model_container: 2
2025-02-24 06:48:15,810:INFO:_display_container: 2
2025-02-24 06:48:15,810:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-02-24 06:48:15,810:INFO:create_model() successfully completed......................................
2025-02-24 06:48:15,994:INFO:SubProcess create_model() end ==================================
2025-02-24 06:48:15,995:INFO:Creating metrics dataframe
2025-02-24 06:48:16,006:INFO:Initializing Naive Bayes
2025-02-24 06:48:16,006:INFO:Total runtime is 0.19158404270807902 minutes
2025-02-24 06:48:16,012:INFO:SubProcess create_model() called ==================================
2025-02-24 06:48:16,012:INFO:Initializing create_model()
2025-02-24 06:48:16,013:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa6012c0890>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa60013e310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:48:16,013:INFO:Checking exceptions
2025-02-24 06:48:16,013:INFO:Importing libraries
2025-02-24 06:48:16,013:INFO:Copying training dataset
2025-02-24 06:48:16,020:INFO:Defining folds
2025-02-24 06:48:16,020:INFO:Declaring metric variables
2025-02-24 06:48:16,029:INFO:Importing untrained model
2025-02-24 06:48:16,038:INFO:Naive Bayes Imported successfully
2025-02-24 06:48:16,056:INFO:Starting cross validation
2025-02-24 06:48:16,059:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:48:16,275:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:16,275:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:16,279:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:16,279:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:16,284:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:16,284:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:16,526:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:16,528:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:16,531:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:16,533:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:16,536:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:16,538:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:16,746:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:16,751:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:16,757:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:16,777:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:16,782:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:16,787:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:17,026:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:17,030:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:17,032:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:17,038:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:17,040:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:17,049:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:17,332:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:17,336:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:17,341:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:17,391:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:17,396:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:17,401:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:17,418:INFO:Calculating mean and std
2025-02-24 06:48:17,419:INFO:Creating metrics dataframe
2025-02-24 06:48:17,428:INFO:Uploading results into container
2025-02-24 06:48:17,429:INFO:Uploading model into container now
2025-02-24 06:48:17,430:INFO:_master_model_container: 3
2025-02-24 06:48:17,431:INFO:_display_container: 2
2025-02-24 06:48:17,431:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-02-24 06:48:17,431:INFO:create_model() successfully completed......................................
2025-02-24 06:48:17,649:INFO:SubProcess create_model() end ==================================
2025-02-24 06:48:17,650:INFO:Creating metrics dataframe
2025-02-24 06:48:17,659:INFO:Initializing Decision Tree Classifier
2025-02-24 06:48:17,660:INFO:Total runtime is 0.21914275884628295 minutes
2025-02-24 06:48:17,669:INFO:SubProcess create_model() called ==================================
2025-02-24 06:48:17,669:INFO:Initializing create_model()
2025-02-24 06:48:17,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa6012c0890>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa60013e310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:48:17,669:INFO:Checking exceptions
2025-02-24 06:48:17,669:INFO:Importing libraries
2025-02-24 06:48:17,669:INFO:Copying training dataset
2025-02-24 06:48:17,679:INFO:Defining folds
2025-02-24 06:48:17,679:INFO:Declaring metric variables
2025-02-24 06:48:17,690:INFO:Importing untrained model
2025-02-24 06:48:17,701:INFO:Decision Tree Classifier Imported successfully
2025-02-24 06:48:17,722:INFO:Starting cross validation
2025-02-24 06:48:17,725:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:48:18,136:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:18,143:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:18,149:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:18,164:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:18,174:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:18,183:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:18,577:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:18,590:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:18,605:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:18,607:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:18,613:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:18,618:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:18,913:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:18,918:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:18,923:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:18,939:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:18,944:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:18,949:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:19,160:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:19,166:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:19,171:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:19,186:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:19,191:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:19,196:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:19,409:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:19,417:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:19,422:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:19,429:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:19,433:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:19,436:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:19,448:INFO:Calculating mean and std
2025-02-24 06:48:19,449:INFO:Creating metrics dataframe
2025-02-24 06:48:19,451:INFO:Uploading results into container
2025-02-24 06:48:19,452:INFO:Uploading model into container now
2025-02-24 06:48:19,452:INFO:_master_model_container: 4
2025-02-24 06:48:19,452:INFO:_display_container: 2
2025-02-24 06:48:19,453:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-02-24 06:48:19,453:INFO:create_model() successfully completed......................................
2025-02-24 06:48:19,650:INFO:SubProcess create_model() end ==================================
2025-02-24 06:48:19,650:INFO:Creating metrics dataframe
2025-02-24 06:48:19,657:INFO:Initializing SVM - Linear Kernel
2025-02-24 06:48:19,657:INFO:Total runtime is 0.2524388074874878 minutes
2025-02-24 06:48:19,663:INFO:SubProcess create_model() called ==================================
2025-02-24 06:48:19,663:INFO:Initializing create_model()
2025-02-24 06:48:19,663:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa6012c0890>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa60013e310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:48:19,663:INFO:Checking exceptions
2025-02-24 06:48:19,663:INFO:Importing libraries
2025-02-24 06:48:19,664:INFO:Copying training dataset
2025-02-24 06:48:19,671:INFO:Defining folds
2025-02-24 06:48:19,671:INFO:Declaring metric variables
2025-02-24 06:48:19,677:INFO:Importing untrained model
2025-02-24 06:48:19,686:INFO:SVM - Linear Kernel Imported successfully
2025-02-24 06:48:19,698:INFO:Starting cross validation
2025-02-24 06:48:19,701:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:48:20,043:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:20,046:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:20,050:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:20,053:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:20,056:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:20,056:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:20,058:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:20,063:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:20,065:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:20,068:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:20,390:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:20,392:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:20,395:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:20,397:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:20,397:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:20,399:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:20,402:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:20,402:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:20,404:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:20,406:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:20,760:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:20,762:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:20,767:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:20,770:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:20,770:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:20,773:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:20,773:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:20,779:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:20,781:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:20,794:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:21,102:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:21,105:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:21,110:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:21,113:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:21,116:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:21,130:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:21,132:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:21,137:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:21,140:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:21,143:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:21,436:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:21,438:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:21,444:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:21,447:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:21,450:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:21,482:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:21,484:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:21,487:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:21,488:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:21,490:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:21,503:INFO:Calculating mean and std
2025-02-24 06:48:21,505:INFO:Creating metrics dataframe
2025-02-24 06:48:21,508:INFO:Uploading results into container
2025-02-24 06:48:21,508:INFO:Uploading model into container now
2025-02-24 06:48:21,509:INFO:_master_model_container: 5
2025-02-24 06:48:21,509:INFO:_display_container: 2
2025-02-24 06:48:21,509:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-02-24 06:48:21,509:INFO:create_model() successfully completed......................................
2025-02-24 06:48:21,700:INFO:SubProcess create_model() end ==================================
2025-02-24 06:48:21,700:INFO:Creating metrics dataframe
2025-02-24 06:48:21,708:INFO:Initializing Ridge Classifier
2025-02-24 06:48:21,709:INFO:Total runtime is 0.286626148223877 minutes
2025-02-24 06:48:21,715:INFO:SubProcess create_model() called ==================================
2025-02-24 06:48:21,716:INFO:Initializing create_model()
2025-02-24 06:48:21,716:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa6012c0890>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa60013e310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:48:21,716:INFO:Checking exceptions
2025-02-24 06:48:21,716:INFO:Importing libraries
2025-02-24 06:48:21,716:INFO:Copying training dataset
2025-02-24 06:48:21,724:INFO:Defining folds
2025-02-24 06:48:21,725:INFO:Declaring metric variables
2025-02-24 06:48:21,731:INFO:Importing untrained model
2025-02-24 06:48:21,738:INFO:Ridge Classifier Imported successfully
2025-02-24 06:48:21,756:INFO:Starting cross validation
2025-02-24 06:48:21,759:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:48:21,967:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:21,970:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:21,975:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:21,977:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:21,977:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:21,979:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:21,980:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:21,984:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:21,987:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:21,990:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,187:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:22,190:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,195:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,197:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:22,200:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,206:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:22,209:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,215:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,217:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:22,220:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,411:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:22,413:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,419:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:22,420:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,421:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,422:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:22,425:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,426:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,428:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:22,431:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,660:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:22,663:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,670:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,673:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:22,673:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:22,676:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,676:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,682:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,685:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:22,691:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,880:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:22,883:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,888:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,891:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:22,893:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,896:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:22,899:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,903:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,905:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:22,907:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:22,914:INFO:Calculating mean and std
2025-02-24 06:48:22,916:INFO:Creating metrics dataframe
2025-02-24 06:48:22,920:INFO:Uploading results into container
2025-02-24 06:48:22,921:INFO:Uploading model into container now
2025-02-24 06:48:22,921:INFO:_master_model_container: 6
2025-02-24 06:48:22,922:INFO:_display_container: 2
2025-02-24 06:48:22,922:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-02-24 06:48:22,922:INFO:create_model() successfully completed......................................
2025-02-24 06:48:23,104:INFO:SubProcess create_model() end ==================================
2025-02-24 06:48:23,105:INFO:Creating metrics dataframe
2025-02-24 06:48:23,114:INFO:Initializing Random Forest Classifier
2025-02-24 06:48:23,117:INFO:Total runtime is 0.310095489025116 minutes
2025-02-24 06:48:23,123:INFO:SubProcess create_model() called ==================================
2025-02-24 06:48:23,123:INFO:Initializing create_model()
2025-02-24 06:48:23,123:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa6012c0890>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa60013e310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:48:23,123:INFO:Checking exceptions
2025-02-24 06:48:23,123:INFO:Importing libraries
2025-02-24 06:48:23,123:INFO:Copying training dataset
2025-02-24 06:48:23,132:INFO:Defining folds
2025-02-24 06:48:23,132:INFO:Declaring metric variables
2025-02-24 06:48:23,141:INFO:Importing untrained model
2025-02-24 06:48:23,148:INFO:Random Forest Classifier Imported successfully
2025-02-24 06:48:23,160:INFO:Starting cross validation
2025-02-24 06:48:23,163:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:48:24,119:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:24,124:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:24,126:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:24,132:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:24,160:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:24,165:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:24,168:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:24,170:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:25,104:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:25,108:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:25,109:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:25,112:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:25,128:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:25,133:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:25,136:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:25,139:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:26,077:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:26,082:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:26,086:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:26,087:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:26,091:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:26,096:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:27,052:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:27,055:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:27,057:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:27,059:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:27,060:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:27,062:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:27,062:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:27,065:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:28,030:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:28,030:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:28,035:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:28,036:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:28,037:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:28,038:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:28,040:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:28,041:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:28,052:INFO:Calculating mean and std
2025-02-24 06:48:28,056:INFO:Creating metrics dataframe
2025-02-24 06:48:28,059:INFO:Uploading results into container
2025-02-24 06:48:28,060:INFO:Uploading model into container now
2025-02-24 06:48:28,060:INFO:_master_model_container: 7
2025-02-24 06:48:28,060:INFO:_display_container: 2
2025-02-24 06:48:28,061:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-02-24 06:48:28,061:INFO:create_model() successfully completed......................................
2025-02-24 06:48:28,247:INFO:SubProcess create_model() end ==================================
2025-02-24 06:48:28,247:INFO:Creating metrics dataframe
2025-02-24 06:48:28,256:INFO:Initializing Quadratic Discriminant Analysis
2025-02-24 06:48:28,256:INFO:Total runtime is 0.39575452009836837 minutes
2025-02-24 06:48:28,262:INFO:SubProcess create_model() called ==================================
2025-02-24 06:48:28,263:INFO:Initializing create_model()
2025-02-24 06:48:28,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa6012c0890>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa60013e310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:48:28,263:INFO:Checking exceptions
2025-02-24 06:48:28,263:INFO:Importing libraries
2025-02-24 06:48:28,263:INFO:Copying training dataset
2025-02-24 06:48:28,270:INFO:Defining folds
2025-02-24 06:48:28,270:INFO:Declaring metric variables
2025-02-24 06:48:28,276:INFO:Importing untrained model
2025-02-24 06:48:28,285:INFO:Quadratic Discriminant Analysis Imported successfully
2025-02-24 06:48:28,300:INFO:Starting cross validation
2025-02-24 06:48:28,303:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:48:28,456:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-02-24 06:48:28,459:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-02-24 06:48:28,520:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:28,520:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:28,522:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:28,523:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:28,527:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:28,527:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:28,529:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:28,530:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:28,532:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:28,532:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:28,688:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-02-24 06:48:28,716:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-02-24 06:48:28,751:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:28,754:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:28,759:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:28,761:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:28,764:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:28,808:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:28,811:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:28,818:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:28,822:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:28,825:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:28,996:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-02-24 06:48:29,034:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-02-24 06:48:29,093:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:29,096:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:29,101:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:29,103:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:29,105:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:29,159:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:29,163:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:29,170:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:29,182:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:29,185:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:29,319:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-02-24 06:48:29,437:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-02-24 06:48:29,462:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:29,473:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:29,486:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:29,491:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:29,493:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:29,497:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:29,497:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:29,499:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:29,501:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:29,508:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:29,742:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-02-24 06:48:29,783:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-02-24 06:48:29,863:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:29,866:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:29,881:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:29,884:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:29,887:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:29,909:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:29,911:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:29,917:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:29,921:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:29,924:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:29,935:INFO:Calculating mean and std
2025-02-24 06:48:29,937:INFO:Creating metrics dataframe
2025-02-24 06:48:29,941:INFO:Uploading results into container
2025-02-24 06:48:29,942:INFO:Uploading model into container now
2025-02-24 06:48:29,942:INFO:_master_model_container: 8
2025-02-24 06:48:29,942:INFO:_display_container: 2
2025-02-24 06:48:29,943:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-02-24 06:48:29,943:INFO:create_model() successfully completed......................................
2025-02-24 06:48:30,155:INFO:SubProcess create_model() end ==================================
2025-02-24 06:48:30,155:INFO:Creating metrics dataframe
2025-02-24 06:48:30,164:INFO:Initializing Ada Boost Classifier
2025-02-24 06:48:30,164:INFO:Total runtime is 0.4275493462880453 minutes
2025-02-24 06:48:30,172:INFO:SubProcess create_model() called ==================================
2025-02-24 06:48:30,172:INFO:Initializing create_model()
2025-02-24 06:48:30,172:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa6012c0890>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa60013e310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:48:30,172:INFO:Checking exceptions
2025-02-24 06:48:30,172:INFO:Importing libraries
2025-02-24 06:48:30,172:INFO:Copying training dataset
2025-02-24 06:48:30,186:INFO:Defining folds
2025-02-24 06:48:30,186:INFO:Declaring metric variables
2025-02-24 06:48:30,195:INFO:Importing untrained model
2025-02-24 06:48:30,202:INFO:Ada Boost Classifier Imported successfully
2025-02-24 06:48:30,221:INFO:Starting cross validation
2025-02-24 06:48:30,223:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:48:30,420:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-02-24 06:48:30,559:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-02-24 06:48:30,813:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:30,816:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:30,822:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:30,825:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:30,828:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:30,891:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:30,894:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:30,899:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:30,902:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:30,905:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:31,006:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-02-24 06:48:31,044:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-02-24 06:48:31,320:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:31,322:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:31,328:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:31,331:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:31,334:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:31,353:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:31,356:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:31,361:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:31,364:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:31,367:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:31,496:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-02-24 06:48:31,525:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-02-24 06:48:31,817:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:31,820:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:31,825:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:31,828:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:31,831:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:31,841:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:31,844:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:31,849:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:31,851:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:31,854:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:31,998:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-02-24 06:48:32,014:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-02-24 06:48:32,348:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:32,350:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:32,355:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:32,362:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:32,407:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:32,409:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:32,415:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:32,418:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:32,421:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:32,526:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-02-24 06:48:32,571:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-02-24 06:48:32,861:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:32,863:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:32,868:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:32,874:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:32,892:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:32,894:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:32,897:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:32,899:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:32,901:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:32,913:INFO:Calculating mean and std
2025-02-24 06:48:32,914:INFO:Creating metrics dataframe
2025-02-24 06:48:32,916:INFO:Uploading results into container
2025-02-24 06:48:32,916:INFO:Uploading model into container now
2025-02-24 06:48:32,917:INFO:_master_model_container: 9
2025-02-24 06:48:32,917:INFO:_display_container: 2
2025-02-24 06:48:32,917:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-02-24 06:48:32,917:INFO:create_model() successfully completed......................................
2025-02-24 06:48:33,101:INFO:SubProcess create_model() end ==================================
2025-02-24 06:48:33,101:INFO:Creating metrics dataframe
2025-02-24 06:48:33,113:INFO:Initializing Gradient Boosting Classifier
2025-02-24 06:48:33,113:INFO:Total runtime is 0.476696793238322 minutes
2025-02-24 06:48:33,119:INFO:SubProcess create_model() called ==================================
2025-02-24 06:48:33,119:INFO:Initializing create_model()
2025-02-24 06:48:33,119:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa6012c0890>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa60013e310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:48:33,119:INFO:Checking exceptions
2025-02-24 06:48:33,119:INFO:Importing libraries
2025-02-24 06:48:33,119:INFO:Copying training dataset
2025-02-24 06:48:33,127:INFO:Defining folds
2025-02-24 06:48:33,127:INFO:Declaring metric variables
2025-02-24 06:48:33,133:INFO:Importing untrained model
2025-02-24 06:48:33,142:INFO:Gradient Boosting Classifier Imported successfully
2025-02-24 06:48:33,154:INFO:Starting cross validation
2025-02-24 06:48:33,157:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:48:41,414:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:41,416:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:41,421:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:41,423:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:41,426:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:41,547:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:41,560:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:41,571:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:41,582:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:50,725:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:50,729:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:50,735:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:50,738:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:50,741:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:50,917:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:50,923:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:50,928:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:50,931:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:50,933:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:59,585:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:59,588:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:59,592:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:59,595:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:48:59,597:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:59,982:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:48:59,984:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:59,988:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:48:59,993:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:08,465:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:49:08,467:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:08,473:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:08,478:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:08,851:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:49:08,854:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:08,859:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:08,862:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:08,866:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:16,829:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:49:16,831:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:16,836:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:16,840:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:17,045:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:49:17,046:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:17,049:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:17,053:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:17,062:INFO:Calculating mean and std
2025-02-24 06:49:17,066:INFO:Creating metrics dataframe
2025-02-24 06:49:17,070:INFO:Uploading results into container
2025-02-24 06:49:17,071:INFO:Uploading model into container now
2025-02-24 06:49:17,072:INFO:_master_model_container: 10
2025-02-24 06:49:17,072:INFO:_display_container: 2
2025-02-24 06:49:17,073:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-02-24 06:49:17,073:INFO:create_model() successfully completed......................................
2025-02-24 06:49:17,445:INFO:SubProcess create_model() end ==================================
2025-02-24 06:49:17,445:INFO:Creating metrics dataframe
2025-02-24 06:49:17,457:INFO:Initializing Linear Discriminant Analysis
2025-02-24 06:49:17,457:INFO:Total runtime is 1.2157689253489177 minutes
2025-02-24 06:49:17,465:INFO:SubProcess create_model() called ==================================
2025-02-24 06:49:17,465:INFO:Initializing create_model()
2025-02-24 06:49:17,465:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa6012c0890>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa60013e310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:49:17,465:INFO:Checking exceptions
2025-02-24 06:49:17,465:INFO:Importing libraries
2025-02-24 06:49:17,465:INFO:Copying training dataset
2025-02-24 06:49:17,476:INFO:Defining folds
2025-02-24 06:49:17,476:INFO:Declaring metric variables
2025-02-24 06:49:17,489:INFO:Importing untrained model
2025-02-24 06:49:17,497:INFO:Linear Discriminant Analysis Imported successfully
2025-02-24 06:49:17,512:INFO:Starting cross validation
2025-02-24 06:49:17,514:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:49:17,923:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:49:17,926:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:17,934:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:17,942:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:17,944:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:17,954:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:49:17,956:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:17,980:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:17,984:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:17,992:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:18,314:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:49:18,316:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:18,330:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:18,333:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:18,342:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:18,373:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:49:18,381:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:18,393:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:18,403:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:18,406:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:18,642:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:49:18,652:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:18,663:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:18,666:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:18,668:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:18,825:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:49:18,830:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:18,841:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:18,844:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:18,850:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:18,971:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:49:18,974:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:18,979:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:18,981:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:18,984:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:19,071:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:49:19,073:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:19,078:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:19,081:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:19,083:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:19,202:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:49:19,205:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:19,210:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:19,213:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:19,216:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:19,269:WARNING:/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-02-24 06:49:19,270:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:19,274:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:19,275:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:19,277:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:19,287:INFO:Calculating mean and std
2025-02-24 06:49:19,289:INFO:Creating metrics dataframe
2025-02-24 06:49:19,291:INFO:Uploading results into container
2025-02-24 06:49:19,292:INFO:Uploading model into container now
2025-02-24 06:49:19,292:INFO:_master_model_container: 11
2025-02-24 06:49:19,292:INFO:_display_container: 2
2025-02-24 06:49:19,293:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-02-24 06:49:19,293:INFO:create_model() successfully completed......................................
2025-02-24 06:49:19,500:INFO:SubProcess create_model() end ==================================
2025-02-24 06:49:19,500:INFO:Creating metrics dataframe
2025-02-24 06:49:19,510:INFO:Initializing Extra Trees Classifier
2025-02-24 06:49:19,510:INFO:Total runtime is 1.249984625975291 minutes
2025-02-24 06:49:19,517:INFO:SubProcess create_model() called ==================================
2025-02-24 06:49:19,518:INFO:Initializing create_model()
2025-02-24 06:49:19,518:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa6012c0890>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa60013e310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:49:19,518:INFO:Checking exceptions
2025-02-24 06:49:19,518:INFO:Importing libraries
2025-02-24 06:49:19,518:INFO:Copying training dataset
2025-02-24 06:49:19,525:INFO:Defining folds
2025-02-24 06:49:19,526:INFO:Declaring metric variables
2025-02-24 06:49:19,534:INFO:Importing untrained model
2025-02-24 06:49:19,542:INFO:Extra Trees Classifier Imported successfully
2025-02-24 06:49:19,556:INFO:Starting cross validation
2025-02-24 06:49:19,559:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:49:20,799:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:20,807:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:20,807:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:20,812:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:20,813:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:20,818:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:21,744:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:21,749:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:21,752:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:21,755:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:21,793:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:21,799:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:21,803:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:22,673:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:22,678:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:22,684:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:22,740:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:22,746:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:22,751:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:23,700:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:23,705:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:23,708:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:23,709:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:23,711:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:23,714:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:23,720:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:24,676:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:24,682:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:24,687:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:24,706:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:24,709:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:24,711:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:24,713:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:24,729:INFO:Calculating mean and std
2025-02-24 06:49:24,731:INFO:Creating metrics dataframe
2025-02-24 06:49:24,733:INFO:Uploading results into container
2025-02-24 06:49:24,734:INFO:Uploading model into container now
2025-02-24 06:49:24,735:INFO:_master_model_container: 12
2025-02-24 06:49:24,735:INFO:_display_container: 2
2025-02-24 06:49:24,735:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-02-24 06:49:24,735:INFO:create_model() successfully completed......................................
2025-02-24 06:49:24,942:INFO:SubProcess create_model() end ==================================
2025-02-24 06:49:24,942:INFO:Creating metrics dataframe
2025-02-24 06:49:24,951:INFO:Initializing Extreme Gradient Boosting
2025-02-24 06:49:24,952:INFO:Total runtime is 1.3406782666842143 minutes
2025-02-24 06:49:24,958:INFO:SubProcess create_model() called ==================================
2025-02-24 06:49:24,958:INFO:Initializing create_model()
2025-02-24 06:49:24,958:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa6012c0890>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa60013e310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:49:24,958:INFO:Checking exceptions
2025-02-24 06:49:24,958:INFO:Importing libraries
2025-02-24 06:49:24,959:INFO:Copying training dataset
2025-02-24 06:49:24,969:INFO:Defining folds
2025-02-24 06:49:24,970:INFO:Declaring metric variables
2025-02-24 06:49:24,976:INFO:Importing untrained model
2025-02-24 06:49:24,982:INFO:Extreme Gradient Boosting Imported successfully
2025-02-24 06:49:24,998:INFO:Starting cross validation
2025-02-24 06:49:25,002:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:49:26,575:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:26,581:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:26,584:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:26,586:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:26,587:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:26,592:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:26,594:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:26,597:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:28,107:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:28,112:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:28,117:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:28,185:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:28,191:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:28,196:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:30,214:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:30,219:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:30,222:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:30,224:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:30,333:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:30,631:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:30,636:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:32,226:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:32,231:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:32,234:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:32,237:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:32,240:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:32,245:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:32,247:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:32,253:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:33,904:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:33,908:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:33,913:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:33,930:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:33,933:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:33,936:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:33,943:INFO:Calculating mean and std
2025-02-24 06:49:33,944:INFO:Creating metrics dataframe
2025-02-24 06:49:33,946:INFO:Uploading results into container
2025-02-24 06:49:33,947:INFO:Uploading model into container now
2025-02-24 06:49:33,947:INFO:_master_model_container: 13
2025-02-24 06:49:33,947:INFO:_display_container: 2
2025-02-24 06:49:33,948:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-02-24 06:49:33,948:INFO:create_model() successfully completed......................................
2025-02-24 06:49:34,156:INFO:SubProcess create_model() end ==================================
2025-02-24 06:49:34,157:INFO:Creating metrics dataframe
2025-02-24 06:49:34,170:INFO:Initializing Light Gradient Boosting Machine
2025-02-24 06:49:34,170:INFO:Total runtime is 1.4943143407503765 minutes
2025-02-24 06:49:34,176:INFO:SubProcess create_model() called ==================================
2025-02-24 06:49:34,177:INFO:Initializing create_model()
2025-02-24 06:49:34,177:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa6012c0890>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa60013e310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:49:34,177:INFO:Checking exceptions
2025-02-24 06:49:34,177:INFO:Importing libraries
2025-02-24 06:49:34,177:INFO:Copying training dataset
2025-02-24 06:49:34,186:INFO:Defining folds
2025-02-24 06:49:34,186:INFO:Declaring metric variables
2025-02-24 06:49:34,193:INFO:Importing untrained model
2025-02-24 06:49:34,202:INFO:Light Gradient Boosting Machine Imported successfully
2025-02-24 06:49:34,219:INFO:Starting cross validation
2025-02-24 06:49:34,222:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:49:39,779:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:39,784:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:39,786:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:39,788:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:40,252:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:40,256:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:40,258:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:40,261:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:47,594:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:47,599:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:47,602:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:47,610:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:47,909:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:47,913:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:47,915:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:47,918:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:57,287:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:57,294:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:57,294:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:57,299:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:57,299:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:49:57,302:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:49:57,305:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:02,820:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:02,824:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:02,826:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:50:02,828:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:03,269:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:03,273:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:03,275:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:50:03,277:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:13,268:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:13,270:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:13,275:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:13,276:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:13,279:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:50:13,280:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:13,281:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:13,292:INFO:Calculating mean and std
2025-02-24 06:50:13,294:INFO:Creating metrics dataframe
2025-02-24 06:50:13,296:INFO:Uploading results into container
2025-02-24 06:50:13,296:INFO:Uploading model into container now
2025-02-24 06:50:13,296:INFO:_master_model_container: 14
2025-02-24 06:50:13,297:INFO:_display_container: 2
2025-02-24 06:50:13,297:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-02-24 06:50:13,297:INFO:create_model() successfully completed......................................
2025-02-24 06:50:13,493:INFO:SubProcess create_model() end ==================================
2025-02-24 06:50:13,494:INFO:Creating metrics dataframe
2025-02-24 06:50:13,504:INFO:Initializing Dummy Classifier
2025-02-24 06:50:13,505:INFO:Total runtime is 2.1498971144358316 minutes
2025-02-24 06:50:13,513:INFO:SubProcess create_model() called ==================================
2025-02-24 06:50:13,513:INFO:Initializing create_model()
2025-02-24 06:50:13,513:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa6012c0890>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa60013e310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:50:13,513:INFO:Checking exceptions
2025-02-24 06:50:13,513:INFO:Importing libraries
2025-02-24 06:50:13,513:INFO:Copying training dataset
2025-02-24 06:50:13,524:INFO:Defining folds
2025-02-24 06:50:13,524:INFO:Declaring metric variables
2025-02-24 06:50:13,531:INFO:Importing untrained model
2025-02-24 06:50:13,537:INFO:Dummy Classifier Imported successfully
2025-02-24 06:50:13,555:INFO:Starting cross validation
2025-02-24 06:50:13,559:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-02-24 06:50:13,798:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:13,801:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:13,803:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:13,806:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:50:13,806:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:13,808:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:13,809:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:50:13,811:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,017:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,023:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,026:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:50:14,026:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,028:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,031:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,034:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:50:14,036:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,251:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,255:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,256:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,259:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:50:14,260:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,261:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,266:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:50:14,275:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,508:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,508:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,513:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,513:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,516:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:50:14,516:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:50:14,518:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,518:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,739:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,741:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,744:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,746:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:50:14,746:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,749:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-02-24 06:50:14,749:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,751:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-02-24 06:50:14,767:INFO:Calculating mean and std
2025-02-24 06:50:14,768:INFO:Creating metrics dataframe
2025-02-24 06:50:14,771:INFO:Uploading results into container
2025-02-24 06:50:14,771:INFO:Uploading model into container now
2025-02-24 06:50:14,772:INFO:_master_model_container: 15
2025-02-24 06:50:14,772:INFO:_display_container: 2
2025-02-24 06:50:14,772:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-02-24 06:50:14,772:INFO:create_model() successfully completed......................................
2025-02-24 06:50:14,975:INFO:SubProcess create_model() end ==================================
2025-02-24 06:50:14,975:INFO:Creating metrics dataframe
2025-02-24 06:50:15,004:INFO:Initializing create_model()
2025-02-24 06:50:15,005:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa6012c0890>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-02-24 06:50:15,005:INFO:Checking exceptions
2025-02-24 06:50:15,006:INFO:Importing libraries
2025-02-24 06:50:15,006:INFO:Copying training dataset
2025-02-24 06:50:15,016:INFO:Defining folds
2025-02-24 06:50:15,016:INFO:Declaring metric variables
2025-02-24 06:50:15,016:INFO:Importing untrained model
2025-02-24 06:50:15,016:INFO:Declaring custom model
2025-02-24 06:50:15,017:INFO:Ridge Classifier Imported successfully
2025-02-24 06:50:15,019:INFO:Cross validation set to False
2025-02-24 06:50:15,019:INFO:Fitting Model
2025-02-24 06:50:15,117:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-02-24 06:50:15,117:INFO:create_model() successfully completed......................................
2025-02-24 06:50:15,385:INFO:_master_model_container: 15
2025-02-24 06:50:15,385:INFO:_display_container: 2
2025-02-24 06:50:15,386:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-02-24 06:50:15,387:INFO:compare_models() successfully completed......................................
2025-02-24 06:50:15,396:INFO:Initializing plot_model()
2025-02-24 06:50:15,396:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4169, solver='auto',
                tol=0.0001), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-02-24 06:50:15,396:INFO:Checking exceptions
2025-02-24 06:50:15,403:INFO:Preloading libraries
2025-02-24 06:50:15,404:INFO:Copying training dataset
2025-02-24 06:50:15,404:INFO:Plot type: confusion_matrix
2025-02-24 06:50:15,511:INFO:Fitting Model
2025-02-24 06:50:15,512:INFO:Scoring test/hold-out set
2025-02-24 06:50:16,211:INFO:Visual Rendered Successfully
2025-02-24 06:50:16,459:INFO:plot_model() successfully completed......................................
2025-02-24 06:50:16,466:INFO:Initializing plot_model()
2025-02-24 06:50:16,466:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4169, solver='auto',
                tol=0.0001), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-02-24 06:50:16,466:INFO:Checking exceptions
2025-02-24 06:50:26,123:INFO:Initializing plot_model()
2025-02-24 06:50:26,124:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4169, solver='auto',
                tol=0.0001), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-02-24 06:50:26,124:INFO:Checking exceptions
2025-02-24 06:50:34,884:INFO:Initializing plot_model()
2025-02-24 06:50:34,893:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4169, solver='auto',
                tol=0.0001), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-02-24 06:50:34,893:INFO:Checking exceptions
2025-02-24 06:50:34,906:INFO:Preloading libraries
2025-02-24 06:50:34,911:INFO:Copying training dataset
2025-02-24 06:50:34,911:INFO:Plot type: feature
2025-02-24 06:50:35,606:INFO:Visual Rendered Successfully
2025-02-24 06:50:35,982:INFO:plot_model() successfully completed......................................
2025-02-24 06:50:49,806:INFO:Initializing evaluate_model()
2025-02-24 06:50:49,806:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4169, solver='auto',
                tol=0.0001), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-02-24 06:50:49,834:INFO:Initializing plot_model()
2025-02-24 06:50:49,834:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4169, solver='auto',
                tol=0.0001), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-02-24 06:50:49,834:INFO:Checking exceptions
2025-02-24 06:50:49,839:INFO:Preloading libraries
2025-02-24 06:50:49,840:INFO:Copying training dataset
2025-02-24 06:50:49,840:INFO:Plot type: pipeline
2025-02-24 06:50:50,117:INFO:Visual Rendered Successfully
2025-02-24 06:50:50,356:INFO:plot_model() successfully completed......................................
2025-02-24 06:50:50,362:INFO:Initializing predict_model()
2025-02-24 06:50:50,362:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4169, solver='auto',
                tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa5fd9ec180>)
2025-02-24 06:50:50,362:INFO:Checking exceptions
2025-02-24 06:50:50,362:INFO:Preloading libraries
2025-02-24 06:50:50,931:INFO:Initializing predict_model()
2025-02-24 06:50:50,931:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa65cb22190>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4169, solver='auto',
                tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa5fe9d51c0>)
2025-02-24 06:50:50,931:INFO:Checking exceptions
2025-02-24 06:50:50,931:INFO:Preloading libraries
2025-02-24 06:50:50,933:INFO:Set up data.
2025-02-24 06:50:50,944:INFO:Set up index.
2025-02-24 06:50:51,504:INFO:Initializing save_model()
2025-02-24 06:50:51,505:INFO:save_model(model=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4169, solver='auto',
                tol=0.0001), model_name=bank_marketing_job_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'balance', 'day',
                                             'duration', 'campaign', 'pdays',
                                             'previous'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['marital', 'education', 'contact',
                                             'month', 'poutcome'],
                                    transformer=OneHotEncoder(cols=['marital',
                                                                    'education',
                                                                    'contact',
                                                                    'month',
                                                                    'poutcome'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-02-24 06:50:51,505:INFO:Adding model into prep_pipe
2025-02-24 06:50:51,517:INFO:bank_marketing_job_pipeline.pkl saved in current working directory
2025-02-24 06:50:51,547:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'balance', 'day',
                                             'duration', 'campaign', 'pdays',
                                             'previous'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep...
                                    transformer=OneHotEncoder(cols=['marital',
                                                                    'education',
                                                                    'contact',
                                                                    'month',
                                                                    'poutcome'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('trained_model',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 positive=False, random_state=4169,
                                 solver='auto', tol=0.0001))],
         verbose=False)
2025-02-24 06:50:51,547:INFO:save_model() successfully completed......................................
2025-02-24 06:50:51,814:INFO:Initializing load_model()
2025-02-24 06:50:51,814:INFO:load_model(model_name=bank_marketing_job_pipeline, platform=None, authentication=None, verbose=True)
