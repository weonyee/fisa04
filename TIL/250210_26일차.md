### 오늘 한 것

#### Elasticsearch
#### 기술 세미나 준비

  
***

### 배운 내용 정리 learned

#### 엘라스틱서치 elk

- text 자료형: 단어마다 색인
- keyword 자료형: 들어온 문자열을 그대로 색인

- 자료형만 일치하면 각 필드에 배열 넣는 것도 가능
- 자료형만 일치한다면 그 안에 []로 배열처럼 넣은 값도 찾을 수 있음
- 주석이 쿼리 사이에 있으면 에러

- 배열, 중첩된 json은 elk에서 내부적으로 평탄화해서 간직
  - 꼭 필요한 경우: 정적으로 nested라는 별도의 타입을 지정해 사용

- 원소 추가
put : 번호 지정
post : 필요 없음(넣어도 되고 생략해도 됨)


#### 검색 api

- 사용자가 request body 방식을 통해 특정 문서를 검색할 때 요청 본문에 질의 내용을 추가하여 검색하는 **RESTful API 방식인 QueryDSL**을 사용
- 검색할 컬럼과 검색어를 JSON 형태로 바디에 전달
- 복잡하고 길어진 쿼리 조건에 적합
- 질의를 JSON 방식으로 표현
- JSON 형식으로 다양한 표현 가능, 가독성 높음
- 현업에서 선호나늡 아식
- 쿼리 조건을 여러 개 만들거나, 통계를 위한 집계 시 권장됨


**match 쿼리**
- 쿼리를 수행하기 전에 먼저 분석기를 통해 text를 분석한 후 검색 수행
- **match_all** : 해당 인덱스의 모든 doc 검색
- **match** : data가 포함된 모든 doc 검색
- **match_phrase** : 순서 고려 검색 수행
- **query_string** 

**bool 쿼리**
- 여러 쿼리를 조합한 결과를 요청할 때 사용
- **must**
- **must_not**
- **should** : 가산점 0
- **filter** : 조건을 포함하는 문서 검색


#### 텍스트 분석
- elk에 저장되는 doc를 필드 별로 역인덱스 생성
-> 문자열 필드가 저장될 때 데이터에서 검색어 토큰을 저장하기 위해 거치는 모든 단계
-> 데이터 입력 -> 필터링 -> 토크나이저 -> 토큰 필터

- 캐릭터필터 & 토크나이저 & 토큰필터로 구성

**기본 애널라이저**

        POST _analyze
        {
          "analyzer": "standard",
          "text": "Hello, HELLO, World!"
        }


**tokenizer type**
hello world
- keyword: 통째로
  - 'hello world'
- ngram: n개의 글자마다 자르기
  - 'he' 'el' 'll' 'lo' ...
- edge_ngram: 토큰의 시작 글자를 단어의 시작 글자로 고정시켜 생성
  - 'he' 'hel' 'hell' 'hello' 'wo' 'wor' 'worl' 'world'


+) 
char_filter: ["html_strip"] :-> html을 우리가 볼 수 있는 문자열로 변환

token_chars = ["letter"] :-> 특수문자 제외

***


### 자습 Self Study

#### 기술세미나 준비
#### XAI

**1. 모델기반 XAI**
   
결정트리

회귀 모델

**2. 모델독립적 XAI**

Lime

shap

PDP(partial dependence plots)

**3. 시각화 기법**

feature importance visualization

activation maps and heatmaps : CNN에서 자주 사용

saliency map

**4. 설명가능한 신경망**

explainable deep learning model

transparent neural network


**5. 대화형 설명**: 사용자가 모델 예측 이해하고 모델의 예측 재조정(상호작용)

interactive LIME

**6. 회귀 분석**: 규제 조건을 사용하여 모델이 결정을 내린 이유를 설명하는 방식
