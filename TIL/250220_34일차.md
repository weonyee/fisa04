### 오늘 한 것

#### ML 분류 알고리즘

#### ML 지도학습 scikitlearn

#### 기술세미나 준비


***

### 배운 내용

#### Adaptive Linear Neuron Adalin

활성화함수를 갈아끼울 수 있는 뉴런

        class AdalineGD(object):
         
            def __init__(self, eta=0.01, n_iter=50, random_state=1):
                self.eta= eta
                self.n_iter = n_iter
                self.random_state=random_state
        
            def fit(self, X, y):
                rgen = np.random.RandomState(self.random_state)
                self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])
                self.cost_ = [] # 에포크를 학습할 때마다 누적한 비용의 누적합 저장
        
                for _ in range(self.n_iter):
                    net_input = self.net_input(X)
                    output = self.activation(net_input)
                    errors = (y - output)
                    self.w_[1:] += self.eta * X.T.dot(errors)
                    self.w_[0] += self.eta * errors.sum()
                    cost = (errors**2).sum() / 2.0
                    self.cost_.append(cost)
                return self
        
            # net_input - 학습이 완료된 모델에 새로 들어온 데이터를 계산하는 함수
            def net_input(self, X):
                return np.dot(X, self.w_[1:]) + self.w_[0]
        
            # 활성화함수 - 선형함수 사용 - 비용함수를 미분으로 측정 가능해짐
            def activation(self, X):
                return X
        
            # predict - 계산의 결과를 출력하는 함수
            def predict(self, X):
                return np.where(self.activation(self.net_input(X)) >= 0.1, 1, -1)


eta=0.01 => 기존 학습의 1%만큼 반영해서 다음 번 학습에 수행



#### ScikitLearn

- 머신러닝 관련 기술을 통일되고 쉬운 인터페이스로 사용할 수 있게 해주는 라이브러리

- 사용 방법
1) Scikit_learn에서 적절한 estimator 클래스를 import해서 모델의 클래스 선택
2) 클래스를 원하는 값으로 인스턴스화해서 모델의 하이퍼파라미터 선택
3) 데이터를 특징 배열과 대상 벡터로 배치
4) 모델 인스턴스의 fit() 메소드로 모델을 데이터에 적용
5) 모델을 새 데이터에 적용

***

#### 머신러닝

**모델링 과정**

데이터 전처리 > 데이터 셋 분리 > 모델 생성 및 학습 > 예측 수행 > 평가

**데이터 셋 분리**
- 학습 데이터
    - 많을수록 유리
- 테스트 데이터
    - 머신러닝 모델의 예측 성능 평가를 위함
- 검증 데이터
    - 학습을 중단할 시점 결정 위한 데이터셋
 
**하이퍼파라미터 튜닝 - 주요 hyperparameter**
- test_size: validation set에 할당할 비율
- stratify: 분할된 샘플의 class 개수가 동일한 비율로 유지
- random_state: 랜덤 시드값
- shuffle: 셔플 옵션


**Logistic Regression**
- 선형 회귀 방식을 이용한 **이진 분류** 알고리즘
- 분류 레이블: 0 or 1 -> 0~1 범위를 예측 결과로 가지는 모델 필요


**규제를 사용해 과대적합 피하기**

= 지금까지의 학습으로 만들어진 결정경계가 다시 데이터를 받아들일 때 중요한 패턴만 취하도록 **강제**하는 역할
- 훈련 데이터를 여러 번 반복학습하고 나면 어느 순간부터는 모델의 일반화 성능은 떨어짐
- 훈련 데이터에만 너무 높은 적중률..
- **L1 규제** : 가중치의 절댓값에 비례하도록 비용 추가
- **L2 규제** : 가중치의 제곱에 비례하도록 비용 추가


