## 오늘 한 것

### Pytorch CNN

### YOLO

***

## 배운 내용

**풀링레이어**

- 이미지를 구성하는 픽셀 중 인접한 픽셀들은 비슷한 정보를 갖고 있는 경우가 많음
- **서브샘플링** : 이미지 크기를 줄이면서 정보만 남기기 위해
- 계산할 정보가 줄어들어 과적합 방지 가능
- MaxPool2D 속성
    - `pool_size=(2,2)`: 높이 2, 너비 2의 사각형 안에서 최댓값만 남기는 연산
    - `strides=(2,2)`: 한 스텝마다 이동하는 크기

### 과적합을 방지하기 위한 방법

**Dropout 레이어**

1. 네트워크의 과적합 방지를 위해 무작위로 뉴런의 부분집합 제거
2. 네트워크가 학습 시에 레이어에 있는 뉴런들은 결과값에 의해 서로 같은 영향을 받음
3. 각 뉴런의 계산 결과를 모두 더해서 나오는 결과값은 한쪽으로 치우치게 됨
4. 방식: 학습 과정에서 확률적으로 일부 뉴런에 대한 연결을 끊고, 테스트할 때는 정상적으로 모든 값을 포함해서 계산
- Dropout은 Dense layer(완전 연결층) 또는 Convolutional layer(합성곱층) 뒤에 적용 가능

### 배치 정규화

- 배치에 대해 각 입력 채널 별 평균과 표준편차를 계산 → 정규화
- 매번 gamma(스케일 파라미터, 얼마 기준으로 스케일을 조정할 것인가), beta(이동 파라미터, 얼마만큼 흩뿌릴 것인가)라는 두 개의 가중치를 함께 학습시키며 정규화 기준을 매 배치마다 변경
    - gamma, beta ≠ 훈련되는 파라미터
- momentum 역할: 평균과 표준편차의 이동 평균 계산 시 이전 값이 주는 가중치

**사용하는 이유**

- 신경망 훈련에서 어려운 것: 네트워크의 가중치를 일정 범위 안에서 유지해야 한다는 것
    - 그렇지 않으면 gradient 폭주(발산)
- 배치마다 스케일 조정(-1~1 사이 값으로 normalization)
- **공변량 변화** - 네트워크가 훈련되며 가중치 값이 랜덤한 초기값과 멀어짐
- 배치 정규화 레이어 ⇒ 매번 새 배치 데이터가 들어갈 때마다 이를 보정
- 주로 Dense layer의 활성화함수 전, convolutional layer 직후에 층의 출력을 정규화

***

### 전이학습

= 한 문제에서 학습한 모델의 지식을 다른 관련 문제에 활용하는 기법

- 대규모 데이터셋으로 미리 학습된 모델을 기반 → 새로운 문제에 맞게 일부 층만 재학습(fine-tuning)하거나 추가
- 학습한 모델의 가중치를 초기값으로 사용 & fine-tuning을 진행 → 학습 시간 단축 & 성능 향상
- **데이터가 적은 경우에도 좋은 성능**

**전이학습의 장점**

- 빠른 학습 속도
    - 이미 학습된 모델을 기반, 초기부터 학습을 진행할 필요 없이 빠르게 수렴
- 데이터 효율성
    - 적은 데이터셋으로도 좋은 성능
- 일반화 성능 향상
    - 대규모 데이터셋에서 학습된 특징 활용 가능
    - 다양한 문제에 대한 일반화 능력 굿
- 리소스 절감
    - 완전한 모델을 처음부터 학습하는 것보다 계산 자원, 시간 절약

**전이학습의 단점**

- 도메인 간의 차이
    - 원래 학습된 데이터와 전이할 대상 데이터의 도메인이 다를 경우, 성능 저하 or 부적절한 특징 추출
- 미세 조정의 어려움
    - 모델을 새로운 데이터에 맞게 조정하는 fine-tuning과정이 까다로움
    - 하이퍼파라미터 설정에 민감
- Bias 전이
    - 기존 모델이 학습한 데이터의 편향이나 오류가 새로운 작업에도 그대로 영향을 미침
- 모델 크기 및 복잡성
    - 전이학습에 사용되는 사전 학습된 모델이 크고 복잡할 경우, 실시간 응용이나 제한된 리소스 환경에서의 적용이 어려움

***

### YOLO

한 번만 보면 이미지 속 사물을 찾아내는 인공지능 모델

- **일반적 객체 탐지 모델**: 이미지를 여러 번 나누어 살펴봄
- **YOLO**: 이미지 전체를 한 번에 보고 자동차, 사람, 동물 같은 객체가 어디있는지 빠르게 찾아냄
    - 속도가 빨라 실시간 탐지에 활용

**YOLO를 사용한 전이학습**

- 사전 학습된 가중치 활용
    - 대규모 데이터셋(예. COCO)에서 사전 학습된 모델을 제공
    - 특정 객체 탐지 작업에 맞게 미세 조정 가능
- 빠른 응용 및 업데이트
    - 전이학습을 통해 새로운 객체나 도메인에 맞게 모델을 빠르게 업데이트
    - 실시간 응용 프로그램에 효과적
- 구조적 특징
    - YOLO의 네트워크는 하나의 통합된 구조를 사용하여 이미지 전체에서 특징을 추출
    - 박스와 클래스 정보를 동시에 예측

### 백본 모델

= 딥러닝 네트워크의 핵심 부분

= 입력 이미지로부터 의미 있는 feature를 추출

- **객체 탐지에서의 역할** 백본 모델이 이미지의 낮은 수준부터 높은 수준까지의 특징을 효과적으로 추출 → 탐지 헤드에서 이 정보를 바탕으로 객체의 위치와 분류 결정
    - Darknet이라는 네트워크를 백본으로 사용
- **전이학습과의 관계** 미리 학습된 백본 모델을 활용 → 모델이 기본적인 시각적 패턴과 특징을 이미 학습한 상태에서 특정 객체 탐지 작업에 맞게 추가학습 진행 가능

### YOLO의 추론 결과물

1. 분할(segmentation)
2. 검출(detection)
3. 분류
4. 트랙킹
5. 포즈 디텍션
6. OBB(Oriented Bounding Box)

**NMS: Non-Maximum Suppression**

비최댓값 억제

- 중첩되는 영역에서 검출되는 클래스 중 가장 confidence가 높은 영역만을 박스로 선택하는 방법
- 각 bounding box의 score가 일정 임계치 이상이면 참이라고 판단하는 경우의 문제
    - 같은 물체에 대하여 많은 bounding box가 잡힐 수도 있음
    - 신뢰도가 가장 높은 하나의 bounding box만 남기고 그 객체와 관련된 나머지 bounding box를 없애는 후처리 과정이 필요
- IoU(Intersection of Union) = 두 박스가 얼마나 겹치는가 = 0~1 사이의 값

**Anchor Box**

- NMS의 문제점 해결
    - object 끼리 겹칠 때 다른 object에 대한 bounding box까지 날라감
- 탐지하려는 객체의 모양을 정해놓고 객체가 탐지되었을 때 어떤 anchor box가 유사한지 판단해서 벡터값 할당
